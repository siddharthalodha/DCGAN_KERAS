{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3cLJSP8tdJf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.2.4)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.2.0)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "graphviz is already the newest version (2.38.0-16ubuntu2).\n",
      "libgraphviz-dev is already the newest version (2.38.0-16ubuntu2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Source : https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/GAN \n",
    "# Project Title : Convert GAN implementation into IPython Notebook\n",
    "\n",
    "# Current Progress\n",
    "# 1. Convert main model,training files\n",
    "# 2. Create HDF5 dataset to be used for training\n",
    "# 3. Trained network on CelebA dataset for 400 epochs\n",
    "# 4. \n",
    "# 5. Add descriptions in code (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q keras\n",
    "import keras\n",
    "\n",
    "!pip install graphviz pydot\n",
    "!apt-get install -y graphviz libgraphviz-dev pydot\n",
    "import graphviz\n",
    "import pydot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install plotnine\n",
    "from plotnine import ggplot\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9851,
     "status": "ok",
     "timestamp": 1528737097314,
     "user": {
      "displayName": "Siddhartha Lodha",
      "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
      "userId": "117940677094137339921"
     },
     "user_tz": -330
    },
    "id": "K70hAckqg0EA",
    "outputId": "24e2f9f9-e7d9-4e39-dd77-a100035b5a7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotnine in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
      "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from plotnine) (0.22.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from plotnine) (1.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from plotnine) (1.14.3)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from plotnine) (2.1.2)\n",
      "Requirement already satisfied: statsmodels>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from plotnine) (0.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotnine) (1.11.0)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine) (0.5.0)\n",
      "Requirement already satisfied: mizani>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.0->plotnine) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.0->plotnine) (2.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->plotnine) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->plotnine) (0.10.0)\n",
      "Requirement already satisfied: palettable in /usr/local/lib/python3.6/dist-packages (from mizani>=0.4.1->plotnine) (3.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TsO9WacsQbMC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Deconv2D, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import Input, Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.utils import generic_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.generic_utils import Progbar\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "#!git clone https://github.com/siddharthalodha/mlsid.git\n",
    "    \n",
    "#!cp -r mlsid/models .\n",
    "#!cp -r mlsid/figures .\n",
    "#!cp -r mlsid/utils .\n",
    "\n",
    "sys.path.append(\"./utils\") # Utils\n",
    "import general_utils\n",
    "import data_utils #Being used for importing data,generating batches (CelebA Data is currently stored in an hdf5 file)\n",
    "%matplotlib inline\n",
    "\n",
    "#!mkdir /figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Hyperparameters for GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ExF9V5Qwdai-"
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "backend=\"tensorflow\" #Specify backend to be used\n",
    "dset=\"celebA\" #Specify dataset to be used, currently supported : mnist/celebA\n",
    "generator=\"upsampling\" #Generator to be used : upsampling/deconv\n",
    "model_name=\"CNN\" #Name of model\n",
    "batch_size=32 #Batch size to be used \n",
    "n_batch_per_epoch=200 #Number of batches per epoch\n",
    "nb_epoch=400 #Number of epochs\n",
    "epoch=10 #Epoch size => Used for progress bars \n",
    "nb_classes=2 #Number of classes\n",
    "do_plot=True #Plotting during execution\n",
    "bn_mode=2 #Batch normalization\n",
    "img_dim=64 #Dimension of image\n",
    "label_smoothing=\"store_true\" #Label smoothing\n",
    "label_flipping=0 #Label flipping\n",
    "noise_scale=0.5 \n",
    "use_mbd=\"store_true\"\n",
    "image_data_format = \"channels_last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading CelebA hdf5 dataset if not already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2012,
     "status": "ok",
     "timestamp": 1528737401530,
     "user": {
      "displayName": "Siddhartha Lodha",
      "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
      "userId": "117940677094137339921"
     },
     "user_tz": -330
    },
    "id": "hH5ebnAGSCyE",
    "outputId": "4dda45f2-95a0-480b-ce61-7f59cae406d9"
   },
   "outputs": [],
   "source": [
    "#Code to download CelebA hdf5 dataset from google drive\n",
    "#!pip install PyDrive\n",
    "\n",
    "#from google.colab import auth\n",
    "#from oauth2client.client import GoogleCredentials\n",
    "#from pydrive.auth import GoogleAuth\n",
    "#from pydrive.drive import GoogleDrive\n",
    "\n",
    "#auth.authenticate_user()\n",
    "#gauth = GoogleAuth()\n",
    "#gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#drive = GoogleDrive(gauth)\n",
    "\n",
    "#fileId = drive.CreateFile({'id': '1cUBPxqU-9Y6f_OAfPwdRmPg7ruZ2sfdk'})\n",
    "#print(fileId['title'])  # CelebA Dataset\n",
    "#fileId.GetContentFile('CelebA_64_data.h5')  # Save Drive file as a local file\n",
    "\n",
    "#fileId = drive.CreateFile({'id': '10B5fIjTwgk1IyXNGbWTzYEXMxnbFixTJ'})\n",
    "#print(fileId['title'])  # CelebA Dataset\n",
    "#fileId.GetContentFile('MNIST.h5')  # Save Drive file as a local file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1535,
     "status": "ok",
     "timestamp": 1528737403105,
     "user": {
      "displayName": "Siddhartha Lodha",
      "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
      "userId": "117940677094137339921"
     },
     "user_tz": -330
    },
    "id": "ElbiB72ccM4Y",
    "outputId": "fba966cf-fee4-4544-d239-658b0f7ce0d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "      raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator function#1 : Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "luzh9Wm2ccMp"
   },
   "outputs": [],
   "source": [
    "def generator_upsampling(noise_dim, img_dim, bn_mode, model_name=\"generator_upsampling\", dset=\"celebA\"):\n",
    "    \"\"\"\n",
    "    Generator model of the DCGAN\n",
    "    args : img_dim (tuple of int) num_chan, height, width\n",
    "           pretr_weights_file (str) file holding pre trained weights\n",
    "    returns : model (keras NN) the Neural Net model\n",
    "    \"\"\"\n",
    "\n",
    "    s = img_dim[1]\n",
    "    f = 512\n",
    "\n",
    "    if dset == \"mnist\":\n",
    "        start_dim = int(s / 4)\n",
    "        nb_upconv = 2\n",
    "    else:\n",
    "        start_dim = int(s / 16)\n",
    "        nb_upconv = 4\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        bn_axis = 1\n",
    "        reshape_shape = (f, start_dim, start_dim)\n",
    "        output_channels = img_dim[0]\n",
    "    else:\n",
    "        reshape_shape = (start_dim, start_dim, f)\n",
    "        bn_axis = -1\n",
    "        output_channels = img_dim[-1]\n",
    "\n",
    "    gen_input = Input(shape=noise_dim, name=\"generator_input\")\n",
    "\n",
    "    x = Dense(f * start_dim * start_dim, input_dim=noise_dim)(gen_input)\n",
    "    x = Reshape(reshape_shape)(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Upscaling blocks\n",
    "    for i in range(nb_upconv):\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        nb_filters = int(f / (2 ** (i + 1)))\n",
    "        x = Conv2D(nb_filters, (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization(axis=1)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(nb_filters, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(output_channels, (3, 3), name=\"gen_Conv2D_final\", padding=\"same\", activation='tanh')(x)\n",
    "\n",
    "    generator_model = Model(inputs=[gen_input], outputs=[x], name=model_name)\n",
    "\n",
    "    return generator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator function#2 : Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_deconv(noise_dim, img_dim, bn_mode, batch_size, model_name=\"generator_deconv\", dset=\"mnist\"):\n",
    "    \"\"\"\n",
    "    Generator model of the DCGAN\n",
    "    args : nb_classes (int) number of classes\n",
    "           img_dim (tuple of int) num_chan, height, width\n",
    "           pretr_weights_file (str) file holding pre trained weights\n",
    "    returns : model (keras NN) the Neural Net model\n",
    "    \"\"\"\n",
    "\n",
    "    assert K.backend() == \"tensorflow\", \"Deconv not implemented with theano\"\n",
    "\n",
    "    s = img_dim[1]\n",
    "    f = 512\n",
    "\n",
    "    if dset == \"mnist\":\n",
    "        start_dim = int(s / 4)\n",
    "        nb_upconv = 2\n",
    "    else:\n",
    "        start_dim = int(s / 16)\n",
    "        nb_upconv = 4\n",
    "\n",
    "    reshape_shape = (start_dim, start_dim, f)\n",
    "    bn_axis = -1\n",
    "    output_channels = img_dim[-1]\n",
    "\n",
    "    gen_input = Input(shape=noise_dim, name=\"generator_input\")\n",
    "\n",
    "    x = Dense(f * start_dim * start_dim, input_dim=noise_dim)(gen_input)\n",
    "    x = Reshape(reshape_shape)(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Transposed conv blocks\n",
    "    for i in range(nb_upconv - 1):\n",
    "        nb_filters = int(f / (2 ** (i + 1)))\n",
    "        s = start_dim * (2 ** (i + 1))\n",
    "        o_shape = (batch_size, s, s, nb_filters)\n",
    "        x = Deconv2D(nb_filters, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Last block\n",
    "    s = start_dim * (2 ** (nb_upconv))\n",
    "    o_shape = (batch_size, s, s, output_channels)\n",
    "    x = Deconv2D(output_channels, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
    "    x = Activation(\"tanh\")(x)\n",
    "\n",
    "    generator_model = Model(inputs=[gen_input], outputs=[x], name=model_name)\n",
    "\n",
    "    return generator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DCGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCGAN(generator, discriminator_model, noise_dim, img_dim):\n",
    "\n",
    "    noise_input = Input(shape=noise_dim, name=\"noise_input\")\n",
    "\n",
    "    generated_image = generator(noise_input)\n",
    "    DCGAN_output = discriminator_model(generated_image)\n",
    "\n",
    "    DCGAN = Model(inputs=[noise_input],\n",
    "                  outputs=[DCGAN_output],\n",
    "                  name=\"DCGAN\")\n",
    "    return DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(model_name, noise_dim, img_dim, bn_mode, batch_size, dset=\"mnist\", use_mbd=False):\n",
    "\n",
    "    if model_name == \"generator_upsampling\":\n",
    "        model = generator_upsampling(noise_dim, img_dim, bn_mode, model_name=model_name, dset=dset)\n",
    "        model.summary()\n",
    "        plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
    "        return model\n",
    "    if model_name == \"generator_deconv\":\n",
    "        model = generator_deconv(noise_dim, img_dim, bn_mode, batch_size, model_name=model_name, dset=dset)\n",
    "        model.summary()\n",
    "        plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
    "        return model\n",
    "    if model_name == \"DCGAN_discriminator\":\n",
    "        model = DCGAN_discriminator(noise_dim, img_dim, bn_mode, model_name=model_name, dset=dset, use_mbd=use_mbd)\n",
    "        model.summary()\n",
    "        plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define discriminator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCGAN_discriminator(noise_dim, img_dim, bn_mode, model_name=\"DCGAN_discriminator\", dset=\"celebA\", use_mbd=False):\n",
    "    \"\"\"\n",
    "    Discriminator model of the DCGAN\n",
    "    args : img_dim (tuple of int) num_chan, height, width\n",
    "           pretr_weights_file (str) file holding pre trained weights\n",
    "    returns : model (keras NN) the Neural Net model\n",
    "    \"\"\"\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = -1\n",
    "\n",
    "    disc_input = Input(shape=img_dim, name=\"discriminator_input\")\n",
    "\n",
    "    if dset == \"mnist\":\n",
    "        list_f = [128]\n",
    "\n",
    "    else:\n",
    "        list_f = [64, 128, 256]\n",
    "\n",
    "    # First conv\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), name=\"disc_Conv2D_1\", padding=\"same\")(disc_input)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    # Next convs\n",
    "    for i, f in enumerate(list_f):\n",
    "        name = \"disc_Conv2D_%s\" % (i + 2)\n",
    "        x = Conv2D(f, (3, 3), strides=(2, 2), name=name, padding=\"same\")(x)\n",
    "        x = BatchNormalization(axis=bn_axis)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    def minb_disc(x):\n",
    "        diffs = K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, [1, 2, 0]), 0)\n",
    "        abs_diffs = K.sum(K.abs(diffs), 2)\n",
    "        x = K.sum(K.exp(-abs_diffs), 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def lambda_output(input_shape):\n",
    "        return input_shape[:2]\n",
    "\n",
    "    num_kernels = 100\n",
    "    dim_per_kernel = 5\n",
    "\n",
    "    M = Dense(num_kernels * dim_per_kernel, use_bias=False, activation=None)\n",
    "    MBD = Lambda(minb_disc, output_shape=lambda_output)\n",
    "\n",
    "    if use_mbd:\n",
    "        x_mbd = M(x)\n",
    "        x_mbd = Reshape((num_kernels, dim_per_kernel))(x_mbd)\n",
    "        x_mbd = MBD(x_mbd)\n",
    "        x = Concatenate(axis=bn_axis)([x, x_mbd])\n",
    "\n",
    "    x = Dense(2, activation='softmax', name=\"disc_dense_2\")(x)\n",
    "\n",
    "    discriminator_model = Model(inputs=[disc_input], outputs=[x], name=model_name)\n",
    "\n",
    "    return discriminator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JYvIBjcLcg_F"
   },
   "outputs": [],
   "source": [
    "def train_GAN(batch_size,n_batch_per_epoch,nb_epoch,generator,model_name,image_data_format,img_dim,bn_mode,label_smoothing,label_flipping,noise_scale,dset,use_mbd,epoch_size):\n",
    "    # Setup environment (logging directory etc)\n",
    "    #general_utils.setup_logging(model_name) #change this if setup_logging moved to separate file\n",
    "\n",
    "    # Load and rescale data\n",
    "    if dset == \"celebA\":\n",
    "        X_real_train = data_utils.load_celebA(img_dim, image_data_format) #change func call if file moved\n",
    "    if dset == \"mnist\":\n",
    "        X_real_train, _, _, _ = data_utils.load_mnist(image_data_format) #change func call if file moved\n",
    "    img_dim = X_real_train.shape[-3:]\n",
    "    noise_dim = (100,)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # Create optimizers\n",
    "        opt_dcgan = Adam(lr=2E-4, beta_1=0.5, beta_2=0.999, epsilon=1e-08)\n",
    "        opt_discriminator = SGD(lr=1E-3, momentum=0.9, nesterov=True)\n",
    "\n",
    "        # Load generator model\n",
    "        generator_model = load(\"generator_%s\" % generator,\n",
    "                                      noise_dim,\n",
    "                                      img_dim,\n",
    "                                      bn_mode,\n",
    "                                      batch_size,\n",
    "                                      dset=dset,\n",
    "                                      use_mbd=use_mbd)\n",
    "        \n",
    "        # Load discriminator model\n",
    "        discriminator_model = load(\"DCGAN_discriminator\",\n",
    "                                          noise_dim,\n",
    "                                          img_dim,\n",
    "                                          bn_mode,\n",
    "                                          batch_size,\n",
    "                                          dset=dset,\n",
    "                                          use_mbd=use_mbd)\n",
    "\n",
    "        generator_model.compile(loss='mse', optimizer=opt_discriminator)\n",
    "        discriminator_model.trainable = False\n",
    "        DCGAN_model = DCGAN(generator_model,\n",
    "                                   discriminator_model,\n",
    "                                   noise_dim,\n",
    "                                   img_dim)\n",
    "        \n",
    "        loss = ['binary_crossentropy']\n",
    "        loss_weights = [1]\n",
    "        DCGAN_model.compile(loss=loss, loss_weights=loss_weights, optimizer=opt_dcgan)\n",
    "\n",
    "        discriminator_model.trainable = True\n",
    "        discriminator_model.compile(loss='binary_crossentropy', optimizer=opt_discriminator)\n",
    "\n",
    "        gen_loss = 100\n",
    "        disc_loss = 100\n",
    "\n",
    "        # Start training\n",
    "        print(\"Start training\")\n",
    "        for e in range(nb_epoch):\n",
    "            #Initialize progbar and batch counter\n",
    "            #progbar = Progbar(epoch_size)\n",
    "            batch_counter = 1\n",
    "            start = time.time()\n",
    "            for X_real_batch in data_utils.gen_batch(X_real_train, batch_size):\n",
    "\n",
    "                # Create a batch to feed the discriminator model\n",
    "                X_disc, y_disc = data_utils.get_disc_batch(X_real_batch,\n",
    "                                                           generator_model,\n",
    "                                                           batch_counter,\n",
    "                                                           batch_size,\n",
    "                                                           noise_dim,\n",
    "                                                           noise_scale=noise_scale,\n",
    "                                                           label_smoothing=label_smoothing,\n",
    "                                                           label_flipping=label_flipping)\n",
    "\n",
    "                # Update the discriminator\n",
    "                disc_loss = discriminator_model.train_on_batch(X_disc, y_disc)\n",
    "\n",
    "                # Create a batch to feed the generator model\n",
    "                X_gen, y_gen = data_utils.get_gen_batch(batch_size, noise_dim, noise_scale=noise_scale)\n",
    "\n",
    "                # Freeze the discriminator\n",
    "                discriminator_model.trainable = False\n",
    "                gen_loss = DCGAN_model.train_on_batch(X_gen, y_gen)\n",
    "                # Unfreeze the discriminator\n",
    "                discriminator_model.trainable = True\n",
    "\n",
    "                batch_counter += 1\n",
    "                #progbar.add(batch_size, values=[(\"D logloss\", disc_loss),\n",
    "                #                                (\"G logloss\", gen_loss)])\n",
    "\n",
    "                 #Save images for visualization\n",
    "                if batch_counter % 100 == 0:\n",
    "                    data_utils.plot_generated_batch(X_real_batch, generator_model,\n",
    "                                                    batch_size, noise_dim, image_data_format)\n",
    "                    \n",
    "                if batch_counter >= n_batch_per_epoch:\n",
    "                    break\n",
    "\n",
    "            print(\"\")\n",
    "            print('Epoch %s/%s, Time: %s, Discriminator loss:%s,Generator loss:%s' % (e + 1, nb_epoch, time.time() - start,disc_loss,gen_loss))\n",
    "\n",
    "            #Save weights for generator,discriminator and DCGAN\n",
    "            if e % 5 == 0:\n",
    "                gen_weights_path = os.path.join('./models/%s/gen_weights_epoch%s.h5' % (model_name, e))\n",
    "                generator_model.save_weights(gen_weights_path, overwrite=True)\n",
    "\n",
    "                disc_weights_path = os.path.join('./models/%s/disc_weights_epoch%s.h5' % (model_name, e))\n",
    "                discriminator_model.save_weights(disc_weights_path, overwrite=True)\n",
    "\n",
    "                DCGAN_weights_path = os.path.join('./models/%s/DCGAN_weights_epoch%s.h5' % (model_name, e))\n",
    "                DCGAN_model.save_weights(DCGAN_weights_path, overwrite=True)\n",
    "    except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1411
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3324,
     "status": "ok",
     "timestamp": 1528737417982,
     "user": {
      "displayName": "Siddhartha Lodha",
      "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
      "userId": "117940677094137339921"
     },
     "user_tz": -330
    },
    "id": "VNolsYjGcsAH",
    "outputId": "ecb51724-1512-459d-fedf-52c5af7e0c69",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 256)         32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       64        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 32, 64)        128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64, 64, 32)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "gen_Conv2D_final (Conv2D)    (None, 64, 64, 3)         867       \n",
      "=================================================================\n",
      "Total params: 3,181,827\n",
      "Trainable params: 3,180,563\n",
      "Non-trainable params: 1,264\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "discriminator_input (InputLayer (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "disc_Conv2D_1 (Conv2D)          (None, 32, 32, 32)   896         discriminator_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         disc_Conv2D_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "disc_Conv2D_2 (Conv2D)          (None, 16, 16, 64)   18496       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   256         disc_Conv2D_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "disc_Conv2D_3 (Conv2D)          (None, 8, 8, 128)    73856       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 128)    512         disc_Conv2D_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 8, 8, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "disc_Conv2D_4 (Conv2D)          (None, 4, 4, 256)    295168      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 256)    1024        disc_Conv2D_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 4, 4, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 500)          2048000     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 100, 5)       0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 100)          0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4196)         0           flatten_1[0][0]                  \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "disc_dense_2 (Dense)            (None, 2)            8394        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,446,730\n",
      "Trainable params: 2,445,770\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "\n",
      "Epoch 1/400, Time: 33.41769456863403, Discriminator loss:1.2269685,Generator loss:1.3847432\n",
      "\n",
      "Epoch 2/400, Time: 26.528018474578857, Discriminator loss:0.97709376,Generator loss:1.9092624\n",
      "\n",
      "Epoch 3/400, Time: 26.492492198944092, Discriminator loss:1.2060373,Generator loss:1.3501065\n",
      "\n",
      "Epoch 4/400, Time: 26.28626036643982, Discriminator loss:0.9497103,Generator loss:1.2151648\n",
      "\n",
      "Epoch 5/400, Time: 26.5520977973938, Discriminator loss:0.91608214,Generator loss:1.2114583\n",
      "\n",
      "Epoch 6/400, Time: 26.311431407928467, Discriminator loss:1.117691,Generator loss:1.5738089\n",
      "\n",
      "Epoch 7/400, Time: 26.29346466064453, Discriminator loss:1.1781392,Generator loss:1.4651277\n",
      "\n",
      "Epoch 8/400, Time: 26.701908588409424, Discriminator loss:0.9702659,Generator loss:2.085391\n",
      "\n",
      "Epoch 9/400, Time: 26.22271490097046, Discriminator loss:1.0706524,Generator loss:1.3010399\n",
      "\n",
      "Epoch 10/400, Time: 26.59523034095764, Discriminator loss:0.9522537,Generator loss:2.3209167\n",
      "\n",
      "Epoch 11/400, Time: 26.389544010162354, Discriminator loss:0.95108783,Generator loss:1.8131495\n",
      "\n",
      "Epoch 12/400, Time: 26.61557102203369, Discriminator loss:1.0057685,Generator loss:1.5829656\n",
      "\n",
      "Epoch 13/400, Time: 26.357173919677734, Discriminator loss:0.9327836,Generator loss:1.3177328\n",
      "\n",
      "Epoch 14/400, Time: 26.504740953445435, Discriminator loss:0.9925593,Generator loss:1.2964176\n",
      "\n",
      "Epoch 15/400, Time: 26.25484323501587, Discriminator loss:1.0548869,Generator loss:1.322839\n",
      "\n",
      "Epoch 16/400, Time: 26.33715033531189, Discriminator loss:0.86890566,Generator loss:1.3350616\n",
      "\n",
      "Epoch 17/400, Time: 26.73111629486084, Discriminator loss:1.0722394,Generator loss:1.6364287\n",
      "\n",
      "Epoch 18/400, Time: 26.29038405418396, Discriminator loss:0.94277203,Generator loss:1.5825745\n",
      "\n",
      "Epoch 19/400, Time: 26.583296298980713, Discriminator loss:0.92338127,Generator loss:1.3204815\n",
      "\n",
      "Epoch 20/400, Time: 26.362741947174072, Discriminator loss:0.9516029,Generator loss:2.201211\n",
      "\n",
      "Epoch 21/400, Time: 26.513402223587036, Discriminator loss:0.93153703,Generator loss:1.8620129\n",
      "\n",
      "Epoch 22/400, Time: 26.54088282585144, Discriminator loss:1.0663834,Generator loss:1.7379029\n",
      "\n",
      "Epoch 23/400, Time: 26.25325107574463, Discriminator loss:1.2516739,Generator loss:1.4095172\n",
      "\n",
      "Epoch 24/400, Time: 26.54665970802307, Discriminator loss:0.89286447,Generator loss:1.2251654\n",
      "\n",
      "Epoch 25/400, Time: 26.190224409103394, Discriminator loss:1.1764234,Generator loss:2.0124962\n",
      "\n",
      "Epoch 26/400, Time: 26.43148374557495, Discriminator loss:1.1030142,Generator loss:1.637326\n",
      "\n",
      "Epoch 27/400, Time: 26.586140871047974, Discriminator loss:0.94511735,Generator loss:1.4970503\n",
      "\n",
      "Epoch 28/400, Time: 26.710233688354492, Discriminator loss:0.8515655,Generator loss:1.5200553\n",
      "\n",
      "Epoch 29/400, Time: 26.408427953720093, Discriminator loss:0.9637321,Generator loss:1.730346\n",
      "\n",
      "Epoch 30/400, Time: 26.456167221069336, Discriminator loss:0.996222,Generator loss:2.070681\n",
      "\n",
      "Epoch 31/400, Time: 26.223948001861572, Discriminator loss:0.9239586,Generator loss:2.0090292\n",
      "\n",
      "Epoch 32/400, Time: 26.277798891067505, Discriminator loss:0.8240478,Generator loss:1.7015374\n",
      "\n",
      "Epoch 33/400, Time: 26.677660703659058, Discriminator loss:0.8144696,Generator loss:1.5737485\n",
      "\n",
      "Epoch 34/400, Time: 26.285977602005005, Discriminator loss:0.9482417,Generator loss:1.7330472\n",
      "\n",
      "Epoch 35/400, Time: 26.607293367385864, Discriminator loss:0.98829204,Generator loss:1.7690002\n",
      "\n",
      "Epoch 36/400, Time: 26.338300704956055, Discriminator loss:1.0482712,Generator loss:1.6189892\n",
      "\n",
      "Epoch 37/400, Time: 26.513054370880127, Discriminator loss:0.9818899,Generator loss:1.244758\n",
      "\n",
      "Epoch 38/400, Time: 26.477761268615723, Discriminator loss:0.85836565,Generator loss:1.7801094\n",
      "\n",
      "Epoch 39/400, Time: 26.28902554512024, Discriminator loss:0.7714932,Generator loss:2.6695564\n",
      "\n",
      "Epoch 40/400, Time: 26.463329315185547, Discriminator loss:0.9406762,Generator loss:1.6920819\n",
      "\n",
      "Epoch 41/400, Time: 26.242111444473267, Discriminator loss:0.82636535,Generator loss:1.6574512\n",
      "\n",
      "Epoch 42/400, Time: 26.716105222702026, Discriminator loss:0.85011995,Generator loss:1.8979461\n",
      "\n",
      "Epoch 43/400, Time: 26.337355852127075, Discriminator loss:0.90081525,Generator loss:1.6286626\n",
      "\n",
      "Epoch 44/400, Time: 26.63957715034485, Discriminator loss:0.81825465,Generator loss:1.9830152\n",
      "\n",
      "Epoch 45/400, Time: 26.40528678894043, Discriminator loss:0.87176675,Generator loss:1.8957669\n",
      "\n",
      "Epoch 46/400, Time: 26.598811626434326, Discriminator loss:0.8529196,Generator loss:1.800175\n",
      "\n",
      "Epoch 47/400, Time: 26.502470016479492, Discriminator loss:0.95095026,Generator loss:1.9501781\n",
      "\n",
      "Epoch 48/400, Time: 26.315232038497925, Discriminator loss:0.90928656,Generator loss:1.8338503\n",
      "\n",
      "Epoch 49/400, Time: 26.530061721801758, Discriminator loss:0.86167985,Generator loss:2.2754939\n",
      "\n",
      "Epoch 50/400, Time: 26.271785736083984, Discriminator loss:0.8026757,Generator loss:1.9904683\n",
      "\n",
      "Epoch 51/400, Time: 26.69021773338318, Discriminator loss:0.82236147,Generator loss:2.4556587\n",
      "\n",
      "Epoch 52/400, Time: 26.198690176010132, Discriminator loss:0.98499036,Generator loss:1.8637137\n",
      "\n",
      "Epoch 53/400, Time: 26.55169367790222, Discriminator loss:0.86495465,Generator loss:1.6194838\n",
      "\n",
      "Epoch 54/400, Time: 26.501153469085693, Discriminator loss:0.814378,Generator loss:2.40842\n",
      "\n",
      "Epoch 55/400, Time: 26.22896718978882, Discriminator loss:1.0558195,Generator loss:2.601362\n",
      "\n",
      "Epoch 56/400, Time: 26.44764232635498, Discriminator loss:0.8601598,Generator loss:1.912344\n",
      "\n",
      "Epoch 57/400, Time: 26.341420888900757, Discriminator loss:0.8468157,Generator loss:2.9345555\n",
      "\n",
      "Epoch 58/400, Time: 26.670512437820435, Discriminator loss:0.83226097,Generator loss:1.9955851\n",
      "\n",
      "Epoch 59/400, Time: 26.227351427078247, Discriminator loss:1.0335293,Generator loss:2.8288577\n",
      "\n",
      "Epoch 60/400, Time: 26.521334171295166, Discriminator loss:0.87612504,Generator loss:2.046683\n",
      "\n",
      "Epoch 61/400, Time: 26.211332321166992, Discriminator loss:0.87109494,Generator loss:2.2497787\n",
      "\n",
      "Epoch 62/400, Time: 26.619470596313477, Discriminator loss:0.9578678,Generator loss:2.0998685\n",
      "\n",
      "Epoch 63/400, Time: 26.487502336502075, Discriminator loss:0.8152206,Generator loss:2.692504\n",
      "\n",
      "Epoch 64/400, Time: 26.383915185928345, Discriminator loss:0.8381003,Generator loss:2.1247494\n",
      "\n",
      "Epoch 65/400, Time: 26.582887411117554, Discriminator loss:0.96249336,Generator loss:2.5637765\n",
      "\n",
      "Epoch 66/400, Time: 26.180137395858765, Discriminator loss:0.88793874,Generator loss:2.8394961\n",
      "\n",
      "Epoch 67/400, Time: 26.814980030059814, Discriminator loss:0.79597193,Generator loss:2.5582886\n",
      "\n",
      "Epoch 68/400, Time: 26.27405619621277, Discriminator loss:0.8537891,Generator loss:2.6621947\n",
      "\n",
      "Epoch 69/400, Time: 26.502296447753906, Discriminator loss:0.866915,Generator loss:2.4643686\n",
      "\n",
      "Epoch 70/400, Time: 26.30836272239685, Discriminator loss:0.77076435,Generator loss:1.7152903\n",
      "\n",
      "Epoch 71/400, Time: 26.249476671218872, Discriminator loss:0.78137726,Generator loss:1.463295\n",
      "\n",
      "Epoch 72/400, Time: 26.894683361053467, Discriminator loss:0.81425583,Generator loss:2.4253793\n",
      "\n",
      "Epoch 73/400, Time: 26.279325008392334, Discriminator loss:0.83213454,Generator loss:2.8810854\n",
      "\n",
      "Epoch 74/400, Time: 26.61291790008545, Discriminator loss:0.91246635,Generator loss:2.1965084\n",
      "\n",
      "Epoch 75/400, Time: 26.145183801651, Discriminator loss:0.9236032,Generator loss:2.2205954\n",
      "\n",
      "Epoch 76/400, Time: 26.61567783355713, Discriminator loss:0.99505305,Generator loss:2.518856\n",
      "\n",
      "Epoch 77/400, Time: 26.308889389038086, Discriminator loss:0.7751806,Generator loss:2.5655146\n",
      "\n",
      "Epoch 78/400, Time: 26.46942400932312, Discriminator loss:0.851856,Generator loss:2.2737064\n",
      "\n",
      "Epoch 79/400, Time: 26.4597384929657, Discriminator loss:0.8057944,Generator loss:2.5055127\n",
      "\n",
      "Epoch 80/400, Time: 26.38805651664734, Discriminator loss:0.7883144,Generator loss:2.8984003\n",
      "\n",
      "Epoch 81/400, Time: 26.641695499420166, Discriminator loss:1.0622251,Generator loss:2.4948478\n",
      "\n",
      "Epoch 82/400, Time: 26.33172082901001, Discriminator loss:0.7830088,Generator loss:1.8747339\n",
      "\n",
      "Epoch 83/400, Time: 26.569793462753296, Discriminator loss:0.75182503,Generator loss:2.0340981\n",
      "\n",
      "Epoch 84/400, Time: 26.251516342163086, Discriminator loss:0.9212127,Generator loss:2.7971933\n",
      "\n",
      "Epoch 85/400, Time: 26.428011894226074, Discriminator loss:0.8882674,Generator loss:2.9536245\n",
      "\n",
      "Epoch 86/400, Time: 26.15916609764099, Discriminator loss:0.8523862,Generator loss:3.0522525\n",
      "\n",
      "Epoch 87/400, Time: 26.29694390296936, Discriminator loss:1.0547125,Generator loss:2.8320334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88/400, Time: 26.772599458694458, Discriminator loss:0.79167,Generator loss:2.7030032\n",
      "\n",
      "Epoch 89/400, Time: 26.22167682647705, Discriminator loss:0.81501883,Generator loss:2.6270204\n",
      "\n",
      "Epoch 90/400, Time: 26.435142993927002, Discriminator loss:0.83117306,Generator loss:3.1011834\n",
      "\n",
      "Epoch 91/400, Time: 26.256758451461792, Discriminator loss:0.8554063,Generator loss:1.6948043\n",
      "\n",
      "Epoch 92/400, Time: 26.724063634872437, Discriminator loss:0.75767374,Generator loss:2.7976346\n",
      "\n",
      "Epoch 93/400, Time: 26.22831439971924, Discriminator loss:0.77659607,Generator loss:3.05973\n",
      "\n",
      "Epoch 94/400, Time: 26.540515184402466, Discriminator loss:0.813272,Generator loss:2.975686\n",
      "\n",
      "Epoch 95/400, Time: 26.377065420150757, Discriminator loss:0.8020232,Generator loss:2.4520545\n",
      "\n",
      "Epoch 96/400, Time: 26.353790760040283, Discriminator loss:0.90616876,Generator loss:2.97692\n",
      "\n",
      "Epoch 97/400, Time: 26.84109663963318, Discriminator loss:0.7447773,Generator loss:2.9339137\n",
      "\n",
      "Epoch 98/400, Time: 26.321821212768555, Discriminator loss:0.7751365,Generator loss:2.65088\n",
      "\n",
      "Epoch 99/400, Time: 26.54800248146057, Discriminator loss:0.8787787,Generator loss:3.2915716\n",
      "\n",
      "Epoch 100/400, Time: 26.39211893081665, Discriminator loss:0.9185326,Generator loss:2.0954483\n",
      "\n",
      "Epoch 101/400, Time: 26.57083797454834, Discriminator loss:0.77031726,Generator loss:2.9478211\n",
      "\n",
      "Epoch 102/400, Time: 26.403559684753418, Discriminator loss:0.8075073,Generator loss:3.5575562\n",
      "\n",
      "Epoch 103/400, Time: 26.24418306350708, Discriminator loss:0.79541326,Generator loss:2.9273875\n",
      "\n",
      "Epoch 104/400, Time: 26.845138788223267, Discriminator loss:0.8043948,Generator loss:2.4643884\n",
      "\n",
      "Epoch 105/400, Time: 26.350321292877197, Discriminator loss:0.89592206,Generator loss:3.0903263\n",
      "\n",
      "Epoch 106/400, Time: 26.55471158027649, Discriminator loss:0.8629508,Generator loss:2.4280558\n",
      "\n",
      "Epoch 107/400, Time: 26.567047834396362, Discriminator loss:0.8186809,Generator loss:3.0984797\n",
      "\n",
      "Epoch 108/400, Time: 26.412266731262207, Discriminator loss:0.86865824,Generator loss:2.2508938\n",
      "\n",
      "Epoch 109/400, Time: 26.225598096847534, Discriminator loss:0.8130558,Generator loss:2.7007213\n",
      "\n",
      "Epoch 110/400, Time: 26.41878318786621, Discriminator loss:0.8223073,Generator loss:2.2183566\n",
      "\n",
      "Epoch 111/400, Time: 26.379239559173584, Discriminator loss:0.8125348,Generator loss:3.2599397\n",
      "\n",
      "Epoch 112/400, Time: 26.314892530441284, Discriminator loss:0.89211,Generator loss:3.0664787\n",
      "\n",
      "Epoch 113/400, Time: 26.69414210319519, Discriminator loss:0.75629264,Generator loss:3.2132983\n",
      "\n",
      "Epoch 114/400, Time: 26.269267559051514, Discriminator loss:0.83012986,Generator loss:2.7770507\n",
      "\n",
      "Epoch 115/400, Time: 26.621284246444702, Discriminator loss:0.9763389,Generator loss:1.9800782\n",
      "\n",
      "Epoch 116/400, Time: 26.308138847351074, Discriminator loss:0.90033364,Generator loss:3.1277723\n",
      "\n",
      "Epoch 117/400, Time: 26.664887189865112, Discriminator loss:0.9030585,Generator loss:3.4130101\n",
      "\n",
      "Epoch 118/400, Time: 26.433565378189087, Discriminator loss:0.80542386,Generator loss:3.0749664\n",
      "\n",
      "Epoch 119/400, Time: 26.52539086341858, Discriminator loss:1.012545,Generator loss:2.4326742\n",
      "\n",
      "Epoch 120/400, Time: 26.21045231819153, Discriminator loss:0.77135086,Generator loss:2.1688256\n",
      "\n",
      "Epoch 121/400, Time: 26.255557775497437, Discriminator loss:0.7705584,Generator loss:3.1681075\n",
      "\n",
      "Epoch 122/400, Time: 26.84726309776306, Discriminator loss:0.88458157,Generator loss:3.2736168\n",
      "\n",
      "Epoch 123/400, Time: 26.234070539474487, Discriminator loss:0.8186736,Generator loss:2.733855\n",
      "\n",
      "Epoch 124/400, Time: 26.598502159118652, Discriminator loss:0.8193141,Generator loss:3.1783798\n",
      "\n",
      "Epoch 125/400, Time: 26.47001576423645, Discriminator loss:0.92151093,Generator loss:2.4375064\n",
      "\n",
      "Epoch 126/400, Time: 26.65401291847229, Discriminator loss:0.931508,Generator loss:2.5005815\n",
      "\n",
      "Epoch 127/400, Time: 26.54908299446106, Discriminator loss:0.8440572,Generator loss:2.8499231\n",
      "\n",
      "Epoch 128/400, Time: 26.422518730163574, Discriminator loss:0.8269864,Generator loss:3.0976768\n",
      "\n",
      "Epoch 129/400, Time: 26.419692993164062, Discriminator loss:0.82941735,Generator loss:2.2645285\n",
      "\n",
      "Epoch 130/400, Time: 26.276334285736084, Discriminator loss:0.77931535,Generator loss:2.7396889\n",
      "\n",
      "Epoch 131/400, Time: 26.435909032821655, Discriminator loss:0.91918325,Generator loss:2.9092584\n",
      "\n",
      "Epoch 132/400, Time: 26.514169454574585, Discriminator loss:0.7620235,Generator loss:3.256016\n",
      "\n",
      "Epoch 133/400, Time: 26.639689922332764, Discriminator loss:0.7791611,Generator loss:3.4772162\n",
      "\n",
      "Epoch 134/400, Time: 26.31962251663208, Discriminator loss:0.8823405,Generator loss:2.8096118\n",
      "\n",
      "Epoch 135/400, Time: 26.586270093917847, Discriminator loss:0.7902652,Generator loss:2.654688\n",
      "\n",
      "Epoch 136/400, Time: 26.29190230369568, Discriminator loss:0.77895904,Generator loss:2.7713683\n",
      "\n",
      "Epoch 137/400, Time: 26.304983615875244, Discriminator loss:0.76103437,Generator loss:3.1133738\n",
      "\n",
      "Epoch 138/400, Time: 26.848345518112183, Discriminator loss:0.7630319,Generator loss:4.1871805\n",
      "\n",
      "Epoch 139/400, Time: 26.207775354385376, Discriminator loss:0.92493653,Generator loss:2.7507534\n",
      "\n",
      "Epoch 140/400, Time: 26.429062366485596, Discriminator loss:0.74803627,Generator loss:2.7052546\n",
      "\n",
      "Epoch 141/400, Time: 26.230435132980347, Discriminator loss:0.77370006,Generator loss:2.7110047\n",
      "\n",
      "Epoch 142/400, Time: 26.542875051498413, Discriminator loss:0.790421,Generator loss:3.6680555\n",
      "\n",
      "Epoch 143/400, Time: 26.39258861541748, Discriminator loss:0.8095998,Generator loss:2.3807166\n",
      "\n",
      "Epoch 144/400, Time: 26.187488555908203, Discriminator loss:0.7916431,Generator loss:3.582697\n",
      "\n",
      "Epoch 145/400, Time: 26.3460373878479, Discriminator loss:0.7922851,Generator loss:2.634184\n",
      "\n",
      "Epoch 146/400, Time: 26.393425226211548, Discriminator loss:0.8676597,Generator loss:2.7946863\n",
      "\n",
      "Epoch 147/400, Time: 26.7235848903656, Discriminator loss:0.8117003,Generator loss:2.6805935\n",
      "\n",
      "Epoch 148/400, Time: 26.429713249206543, Discriminator loss:0.8421033,Generator loss:2.6759675\n",
      "\n",
      "Epoch 149/400, Time: 26.854456901550293, Discriminator loss:0.84996295,Generator loss:2.6697655\n",
      "\n",
      "Epoch 150/400, Time: 26.626169681549072, Discriminator loss:0.76563704,Generator loss:3.250205\n",
      "\n",
      "Epoch 151/400, Time: 26.591121196746826, Discriminator loss:0.78754604,Generator loss:2.3092055\n",
      "\n",
      "Epoch 152/400, Time: 26.900466680526733, Discriminator loss:0.7795566,Generator loss:2.4794824\n",
      "\n",
      "Epoch 153/400, Time: 26.86494731903076, Discriminator loss:0.7555914,Generator loss:3.1270945\n",
      "\n",
      "Epoch 154/400, Time: 26.977742671966553, Discriminator loss:0.7792815,Generator loss:3.2208025\n",
      "\n",
      "Epoch 155/400, Time: 26.616604328155518, Discriminator loss:0.91632277,Generator loss:2.5400515\n",
      "\n",
      "Epoch 156/400, Time: 26.723957061767578, Discriminator loss:0.7749382,Generator loss:3.38691\n",
      "\n",
      "Epoch 157/400, Time: 26.374847173690796, Discriminator loss:0.7901826,Generator loss:3.0509973\n",
      "\n",
      "Epoch 158/400, Time: 26.571877002716064, Discriminator loss:0.79885554,Generator loss:3.733417\n",
      "\n",
      "Epoch 159/400, Time: 27.199203729629517, Discriminator loss:0.7812135,Generator loss:2.8211865\n",
      "\n",
      "Epoch 160/400, Time: 27.517213106155396, Discriminator loss:0.8554567,Generator loss:3.0259485\n",
      "\n",
      "Epoch 161/400, Time: 26.895702600479126, Discriminator loss:0.7838485,Generator loss:3.0526226\n",
      "\n",
      "Epoch 162/400, Time: 26.899657249450684, Discriminator loss:0.7642418,Generator loss:3.3742044\n",
      "\n",
      "Epoch 163/400, Time: 27.211702346801758, Discriminator loss:0.7854479,Generator loss:2.6164703\n",
      "\n",
      "Epoch 164/400, Time: 26.256678342819214, Discriminator loss:0.86338353,Generator loss:2.528276\n",
      "\n",
      "Epoch 165/400, Time: 26.874461889266968, Discriminator loss:0.7649049,Generator loss:2.9188576\n",
      "\n",
      "Epoch 166/400, Time: 27.11226224899292, Discriminator loss:0.7546071,Generator loss:2.3781838\n",
      "\n",
      "Epoch 167/400, Time: 27.672882318496704, Discriminator loss:0.88091755,Generator loss:2.791254\n",
      "\n",
      "Epoch 168/400, Time: 26.280033826828003, Discriminator loss:0.86554223,Generator loss:3.0633593\n",
      "\n",
      "Epoch 169/400, Time: 26.494248151779175, Discriminator loss:0.78257245,Generator loss:3.0510292\n",
      "\n",
      "Epoch 170/400, Time: 27.56254267692566, Discriminator loss:0.8218931,Generator loss:3.1333864\n",
      "\n",
      "Epoch 171/400, Time: 27.728816509246826, Discriminator loss:0.7858168,Generator loss:3.1631436\n",
      "\n",
      "Epoch 172/400, Time: 26.719745874404907, Discriminator loss:0.8053082,Generator loss:3.8367581\n",
      "\n",
      "Epoch 173/400, Time: 26.340286016464233, Discriminator loss:0.77760065,Generator loss:1.931562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 174/400, Time: 27.47257423400879, Discriminator loss:0.7794107,Generator loss:2.5176098\n",
      "\n",
      "Epoch 175/400, Time: 27.74468469619751, Discriminator loss:0.8559309,Generator loss:2.2982314\n",
      "\n",
      "Epoch 176/400, Time: 27.001818656921387, Discriminator loss:0.8867333,Generator loss:2.7669954\n",
      "\n",
      "Epoch 177/400, Time: 26.711982011795044, Discriminator loss:0.8429191,Generator loss:3.2414093\n",
      "\n",
      "Epoch 178/400, Time: 26.579306840896606, Discriminator loss:0.7627411,Generator loss:2.616054\n",
      "\n",
      "Epoch 179/400, Time: 27.638082027435303, Discriminator loss:0.91610897,Generator loss:2.071127\n",
      "\n",
      "Epoch 180/400, Time: 28.224013328552246, Discriminator loss:0.83256614,Generator loss:3.8216934\n",
      "\n",
      "Epoch 181/400, Time: 27.10747218132019, Discriminator loss:0.767642,Generator loss:3.0596056\n",
      "\n",
      "Epoch 182/400, Time: 26.277152061462402, Discriminator loss:0.93134975,Generator loss:2.4659495\n",
      "\n",
      "Epoch 183/400, Time: 27.326907634735107, Discriminator loss:0.8580449,Generator loss:1.6492671\n",
      "\n",
      "Epoch 184/400, Time: 28.16417145729065, Discriminator loss:0.8271568,Generator loss:3.3813338\n",
      "\n",
      "Epoch 185/400, Time: 28.094257831573486, Discriminator loss:0.7585907,Generator loss:3.0599957\n",
      "\n",
      "Epoch 186/400, Time: 26.406877994537354, Discriminator loss:0.78135955,Generator loss:2.3840299\n",
      "\n",
      "Epoch 187/400, Time: 26.8297336101532, Discriminator loss:0.8765315,Generator loss:3.6706595\n",
      "\n",
      "Epoch 188/400, Time: 28.492969036102295, Discriminator loss:0.78629947,Generator loss:3.9698915\n",
      "\n",
      "Epoch 189/400, Time: 27.5988609790802, Discriminator loss:0.82535493,Generator loss:2.7464213\n",
      "\n",
      "Epoch 190/400, Time: 28.068301677703857, Discriminator loss:0.7667383,Generator loss:3.0324101\n",
      "\n",
      "Epoch 191/400, Time: 26.2173810005188, Discriminator loss:0.8220058,Generator loss:3.2240267\n",
      "\n",
      "Epoch 192/400, Time: 28.684540271759033, Discriminator loss:0.76289,Generator loss:3.2976503\n",
      "\n",
      "Epoch 193/400, Time: 28.32334542274475, Discriminator loss:0.7927083,Generator loss:2.5947838\n",
      "\n",
      "Epoch 194/400, Time: 28.351686000823975, Discriminator loss:0.742916,Generator loss:2.4848292\n",
      "\n",
      "Epoch 195/400, Time: 26.305505514144897, Discriminator loss:0.78363925,Generator loss:2.266994\n",
      "\n",
      "Epoch 196/400, Time: 26.95682191848755, Discriminator loss:0.9003045,Generator loss:2.3773816\n",
      "\n",
      "Epoch 197/400, Time: 28.276316165924072, Discriminator loss:0.8440163,Generator loss:2.8476405\n",
      "\n",
      "Epoch 198/400, Time: 28.55191659927368, Discriminator loss:0.7722648,Generator loss:2.8836956\n",
      "\n",
      "Epoch 199/400, Time: 27.971451997756958, Discriminator loss:0.7434999,Generator loss:3.2252302\n",
      "\n",
      "Epoch 200/400, Time: 26.851309537887573, Discriminator loss:0.77851474,Generator loss:3.4109552\n",
      "\n",
      "Epoch 201/400, Time: 28.238651037216187, Discriminator loss:0.78918076,Generator loss:3.2970777\n",
      "\n",
      "Epoch 202/400, Time: 28.4831702709198, Discriminator loss:0.8085264,Generator loss:3.5071998\n",
      "\n",
      "Epoch 203/400, Time: 28.813722610473633, Discriminator loss:0.8974529,Generator loss:3.2917044\n",
      "\n",
      "Epoch 204/400, Time: 26.26806354522705, Discriminator loss:0.8378696,Generator loss:3.2229757\n",
      "\n",
      "Epoch 205/400, Time: 28.111268997192383, Discriminator loss:0.7803503,Generator loss:2.64191\n",
      "\n",
      "Epoch 206/400, Time: 28.82188653945923, Discriminator loss:0.7616514,Generator loss:3.203004\n",
      "\n",
      "Epoch 207/400, Time: 28.724608421325684, Discriminator loss:0.7986698,Generator loss:3.288848\n",
      "\n",
      "Epoch 208/400, Time: 26.888104915618896, Discriminator loss:0.7270059,Generator loss:3.3472457\n",
      "\n",
      "Epoch 209/400, Time: 27.172282934188843, Discriminator loss:0.8100915,Generator loss:3.379694\n",
      "\n",
      "Epoch 210/400, Time: 28.703873872756958, Discriminator loss:0.7761772,Generator loss:3.2185507\n",
      "\n",
      "Epoch 211/400, Time: 28.79144024848938, Discriminator loss:0.7989352,Generator loss:2.6171863\n",
      "\n",
      "Epoch 212/400, Time: 28.34986448287964, Discriminator loss:0.7866304,Generator loss:2.625331\n",
      "\n",
      "Epoch 213/400, Time: 26.839741945266724, Discriminator loss:0.9316517,Generator loss:2.603362\n",
      "\n",
      "Epoch 214/400, Time: 29.246455907821655, Discriminator loss:0.78406656,Generator loss:2.2806344\n",
      "\n",
      "Epoch 215/400, Time: 28.75587296485901, Discriminator loss:0.74281853,Generator loss:2.8610575\n",
      "\n",
      "Epoch 216/400, Time: 29.03129243850708, Discriminator loss:0.7468676,Generator loss:3.3460035\n",
      "\n",
      "Epoch 217/400, Time: 26.49657154083252, Discriminator loss:0.7669042,Generator loss:3.5177727\n",
      "\n",
      "Epoch 218/400, Time: 29.30552053451538, Discriminator loss:0.8160177,Generator loss:3.7515764\n",
      "\n",
      "Epoch 219/400, Time: 28.59741520881653, Discriminator loss:0.8194163,Generator loss:3.2181156\n",
      "\n",
      "Epoch 220/400, Time: 28.66674828529358, Discriminator loss:0.7707893,Generator loss:3.882925\n",
      "\n",
      "Epoch 221/400, Time: 27.72214388847351, Discriminator loss:0.83841527,Generator loss:2.7913992\n",
      "\n",
      "Epoch 222/400, Time: 28.082879543304443, Discriminator loss:0.7808523,Generator loss:2.9860303\n",
      "\n",
      "Epoch 223/400, Time: 28.27607250213623, Discriminator loss:0.83294636,Generator loss:3.8188214\n",
      "\n",
      "Epoch 224/400, Time: 29.34779405593872, Discriminator loss:0.8579725,Generator loss:3.531169\n",
      "\n",
      "Epoch 225/400, Time: 27.588997840881348, Discriminator loss:0.7853677,Generator loss:3.234479\n",
      "\n",
      "Epoch 226/400, Time: 28.1311194896698, Discriminator loss:0.75327414,Generator loss:3.0313587\n",
      "\n",
      "Epoch 227/400, Time: 26.30528426170349, Discriminator loss:0.77286696,Generator loss:3.0246944\n",
      "\n",
      "Epoch 228/400, Time: 27.261924982070923, Discriminator loss:0.8797238,Generator loss:2.4168994\n",
      "\n",
      "Epoch 229/400, Time: 28.88781213760376, Discriminator loss:0.76375437,Generator loss:3.617787\n",
      "\n",
      "Epoch 230/400, Time: 27.181399822235107, Discriminator loss:0.8022258,Generator loss:2.8553557\n",
      "\n",
      "Epoch 231/400, Time: 29.661404848098755, Discriminator loss:0.7864894,Generator loss:3.631103\n",
      "\n",
      "Epoch 232/400, Time: 28.9664945602417, Discriminator loss:0.804666,Generator loss:3.319967\n",
      "\n",
      "Epoch 233/400, Time: 26.247062921524048, Discriminator loss:0.79394084,Generator loss:4.2799234\n",
      "\n",
      "Epoch 234/400, Time: 26.2930428981781, Discriminator loss:0.7787507,Generator loss:3.0962582\n",
      "\n",
      "Epoch 235/400, Time: 28.570860385894775, Discriminator loss:0.7686266,Generator loss:2.7331853\n",
      "\n",
      "Epoch 236/400, Time: 28.528130769729614, Discriminator loss:0.7659809,Generator loss:2.8059072\n",
      "\n",
      "Epoch 237/400, Time: 29.367366552352905, Discriminator loss:0.7651555,Generator loss:2.7115102\n",
      "\n",
      "Epoch 238/400, Time: 29.61880588531494, Discriminator loss:0.7955407,Generator loss:3.5812097\n",
      "\n",
      "Epoch 239/400, Time: 28.203428983688354, Discriminator loss:0.7945529,Generator loss:3.0724459\n",
      "\n",
      "Epoch 240/400, Time: 28.873852491378784, Discriminator loss:0.7669989,Generator loss:3.2906685\n",
      "\n",
      "Epoch 241/400, Time: 29.484976768493652, Discriminator loss:0.81467223,Generator loss:3.33222\n",
      "\n",
      "Epoch 242/400, Time: 29.98432493209839, Discriminator loss:0.76866454,Generator loss:3.8928432\n",
      "\n",
      "Epoch 243/400, Time: 27.297767162322998, Discriminator loss:0.9567652,Generator loss:2.6628833\n",
      "\n",
      "Epoch 244/400, Time: 29.95738410949707, Discriminator loss:0.73394907,Generator loss:3.386292\n",
      "\n",
      "Epoch 245/400, Time: 29.904692888259888, Discriminator loss:0.7988161,Generator loss:3.7562037\n",
      "\n",
      "Epoch 246/400, Time: 29.367645740509033, Discriminator loss:0.8022852,Generator loss:2.8858485\n",
      "\n",
      "Epoch 247/400, Time: 27.77693462371826, Discriminator loss:0.78553325,Generator loss:2.9555583\n",
      "\n",
      "Epoch 248/400, Time: 29.817519903182983, Discriminator loss:0.9742767,Generator loss:2.853232\n",
      "\n",
      "Epoch 249/400, Time: 29.203056812286377, Discriminator loss:0.79412967,Generator loss:2.9168408\n",
      "\n",
      "Epoch 250/400, Time: 29.19921875, Discriminator loss:0.7698659,Generator loss:3.4453025\n",
      "\n",
      "Epoch 251/400, Time: 28.389662265777588, Discriminator loss:0.8336491,Generator loss:3.3309257\n",
      "\n",
      "Epoch 252/400, Time: 29.27292251586914, Discriminator loss:0.76515067,Generator loss:3.1197934\n",
      "\n",
      "Epoch 253/400, Time: 28.397083282470703, Discriminator loss:0.78445566,Generator loss:3.1420622\n",
      "\n",
      "Epoch 254/400, Time: 29.827565670013428, Discriminator loss:0.81156814,Generator loss:3.65988\n",
      "\n",
      "Epoch 255/400, Time: 30.33877992630005, Discriminator loss:0.85596555,Generator loss:2.937923\n",
      "\n",
      "Epoch 256/400, Time: 26.73190951347351, Discriminator loss:0.81514335,Generator loss:3.0508757\n",
      "\n",
      "Epoch 257/400, Time: 26.3453311920166, Discriminator loss:0.7640492,Generator loss:3.5641127\n",
      "\n",
      "Epoch 258/400, Time: 28.953928470611572, Discriminator loss:0.85701096,Generator loss:2.8912847\n",
      "\n",
      "Epoch 259/400, Time: 28.630675315856934, Discriminator loss:0.75544846,Generator loss:3.662467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 260/400, Time: 30.689592599868774, Discriminator loss:0.80581284,Generator loss:3.5368104\n",
      "\n",
      "Epoch 261/400, Time: 29.147627592086792, Discriminator loss:0.7857642,Generator loss:2.9535532\n",
      "\n",
      "Epoch 262/400, Time: 27.843136310577393, Discriminator loss:0.7407031,Generator loss:3.1959715\n",
      "\n",
      "Epoch 263/400, Time: 26.362658500671387, Discriminator loss:0.8121822,Generator loss:2.8949065\n",
      "\n",
      "Epoch 264/400, Time: 27.008450269699097, Discriminator loss:0.7836006,Generator loss:3.695775\n",
      "\n",
      "Epoch 265/400, Time: 30.08004403114319, Discriminator loss:0.7771136,Generator loss:3.3301504\n",
      "\n",
      "Epoch 266/400, Time: 29.427543878555298, Discriminator loss:0.74555045,Generator loss:3.2042289\n",
      "\n",
      "Epoch 267/400, Time: 28.70937943458557, Discriminator loss:0.83942634,Generator loss:2.8229644\n",
      "\n",
      "Epoch 268/400, Time: 30.050166130065918, Discriminator loss:0.8462744,Generator loss:2.4833374\n",
      "\n",
      "Epoch 269/400, Time: 27.305888414382935, Discriminator loss:1.0224615,Generator loss:2.6308208\n",
      "\n",
      "Epoch 270/400, Time: 26.586183547973633, Discriminator loss:0.86486596,Generator loss:3.4140139\n",
      "\n",
      "Epoch 271/400, Time: 29.414691925048828, Discriminator loss:0.78602207,Generator loss:2.856534\n",
      "\n",
      "Epoch 272/400, Time: 28.420559644699097, Discriminator loss:0.8397182,Generator loss:2.9814692\n",
      "\n",
      "Epoch 273/400, Time: 30.632784605026245, Discriminator loss:0.8160143,Generator loss:2.9709342\n",
      "\n",
      "Epoch 274/400, Time: 29.481548070907593, Discriminator loss:0.7805596,Generator loss:3.3341177\n",
      "\n",
      "Epoch 275/400, Time: 28.235058069229126, Discriminator loss:0.7699483,Generator loss:3.3038673\n",
      "\n",
      "Epoch 276/400, Time: 26.356898069381714, Discriminator loss:0.7720113,Generator loss:3.597776\n",
      "\n",
      "Epoch 277/400, Time: 28.444854259490967, Discriminator loss:0.83378917,Generator loss:3.1616712\n",
      "\n",
      "Epoch 278/400, Time: 29.470428228378296, Discriminator loss:0.7662615,Generator loss:3.2645586\n",
      "\n",
      "Epoch 279/400, Time: 29.699360370635986, Discriminator loss:0.7546886,Generator loss:3.1446762\n",
      "\n",
      "Epoch 280/400, Time: 28.985217809677124, Discriminator loss:0.78118896,Generator loss:3.4169264\n",
      "\n",
      "Epoch 281/400, Time: 30.726738214492798, Discriminator loss:0.8499074,Generator loss:3.8955994\n",
      "\n",
      "Epoch 282/400, Time: 26.17406177520752, Discriminator loss:0.7409409,Generator loss:2.8787704\n",
      "\n",
      "Epoch 283/400, Time: 27.52313542366028, Discriminator loss:0.82729053,Generator loss:3.3547907\n",
      "\n",
      "Epoch 284/400, Time: 30.03858709335327, Discriminator loss:0.7566925,Generator loss:3.5964794\n",
      "\n",
      "Epoch 285/400, Time: 29.696490049362183, Discriminator loss:0.83166003,Generator loss:3.9363565\n",
      "\n",
      "Epoch 286/400, Time: 29.40194821357727, Discriminator loss:0.80399686,Generator loss:4.3868303\n",
      "\n",
      "Epoch 287/400, Time: 30.341607332229614, Discriminator loss:0.8349783,Generator loss:3.1413481\n",
      "\n",
      "Epoch 288/400, Time: 27.636802911758423, Discriminator loss:0.7460082,Generator loss:3.7675333\n",
      "\n",
      "Epoch 289/400, Time: 26.871830463409424, Discriminator loss:0.76858115,Generator loss:4.279786\n",
      "\n",
      "Epoch 290/400, Time: 29.681177616119385, Discriminator loss:0.8486296,Generator loss:2.8656728\n",
      "\n",
      "Epoch 291/400, Time: 28.7703378200531, Discriminator loss:0.7845235,Generator loss:3.4290962\n",
      "\n",
      "Epoch 292/400, Time: 30.979198932647705, Discriminator loss:0.76255405,Generator loss:2.6156182\n",
      "\n",
      "Epoch 293/400, Time: 29.862398624420166, Discriminator loss:0.7525494,Generator loss:3.6552958\n",
      "\n",
      "Epoch 294/400, Time: 28.95657992362976, Discriminator loss:0.8064884,Generator loss:2.7124796\n",
      "\n",
      "Epoch 295/400, Time: 26.334478855133057, Discriminator loss:0.8562843,Generator loss:3.1900928\n",
      "\n",
      "Epoch 296/400, Time: 29.184059858322144, Discriminator loss:0.7729778,Generator loss:2.6770353\n",
      "\n",
      "Epoch 297/400, Time: 29.552109956741333, Discriminator loss:0.7861227,Generator loss:2.5780592\n",
      "\n",
      "Epoch 298/400, Time: 30.254683017730713, Discriminator loss:0.75137985,Generator loss:3.9104552\n",
      "\n",
      "Epoch 299/400, Time: 29.328930377960205, Discriminator loss:0.7634388,Generator loss:3.842306\n",
      "\n",
      "Epoch 300/400, Time: 30.496029138565063, Discriminator loss:0.7390176,Generator loss:3.876419\n",
      "\n",
      "Epoch 301/400, Time: 26.581897258758545, Discriminator loss:0.7823901,Generator loss:3.2318296\n",
      "\n",
      "Epoch 302/400, Time: 29.198750257492065, Discriminator loss:0.80972123,Generator loss:3.5992632\n",
      "\n",
      "Epoch 303/400, Time: 29.984468460083008, Discriminator loss:0.78314173,Generator loss:3.3724198\n",
      "\n",
      "Epoch 304/400, Time: 30.140100240707397, Discriminator loss:0.75492656,Generator loss:4.6415176\n",
      "\n",
      "Epoch 305/400, Time: 28.990243673324585, Discriminator loss:0.7625601,Generator loss:3.7724829\n",
      "\n",
      "Epoch 306/400, Time: 30.891878366470337, Discriminator loss:0.84891224,Generator loss:3.7357173\n",
      "\n",
      "Epoch 307/400, Time: 27.64792537689209, Discriminator loss:0.7964035,Generator loss:3.1267314\n",
      "\n",
      "Epoch 308/400, Time: 28.144847869873047, Discriminator loss:0.72500324,Generator loss:2.583698\n",
      "\n",
      "Epoch 309/400, Time: 30.494421005249023, Discriminator loss:0.8067793,Generator loss:3.0804625\n",
      "\n",
      "Epoch 310/400, Time: 27.57481074333191, Discriminator loss:0.7690407,Generator loss:3.4646077\n",
      "\n",
      "Epoch 311/400, Time: 30.98441433906555, Discriminator loss:0.79350513,Generator loss:4.940711\n",
      "\n",
      "Epoch 312/400, Time: 29.347559213638306, Discriminator loss:0.7662698,Generator loss:2.9509993\n",
      "\n",
      "Epoch 313/400, Time: 29.917836904525757, Discriminator loss:0.7369113,Generator loss:3.6001606\n",
      "\n",
      "Epoch 314/400, Time: 27.12024688720703, Discriminator loss:0.8210132,Generator loss:2.484355\n",
      "\n",
      "Epoch 315/400, Time: 29.93988823890686, Discriminator loss:0.7953224,Generator loss:3.7549539\n",
      "\n",
      "Epoch 316/400, Time: 28.81996512413025, Discriminator loss:0.77045494,Generator loss:3.7414386\n",
      "\n",
      "Epoch 317/400, Time: 30.95017695426941, Discriminator loss:0.761069,Generator loss:2.7171102\n",
      "\n",
      "Epoch 318/400, Time: 28.782896518707275, Discriminator loss:0.7541832,Generator loss:3.9794\n",
      "\n",
      "Epoch 319/400, Time: 30.28075408935547, Discriminator loss:0.7599895,Generator loss:3.4712071\n",
      "\n",
      "Epoch 320/400, Time: 28.105130910873413, Discriminator loss:0.7617624,Generator loss:3.761466\n",
      "\n",
      "Epoch 321/400, Time: 30.366376161575317, Discriminator loss:0.77485883,Generator loss:3.296636\n",
      "\n",
      "Epoch 322/400, Time: 29.160740852355957, Discriminator loss:0.76160204,Generator loss:3.5988064\n",
      "\n",
      "Epoch 323/400, Time: 30.96345853805542, Discriminator loss:0.76937586,Generator loss:2.3213964\n",
      "\n",
      "Epoch 324/400, Time: 28.55836296081543, Discriminator loss:0.76224756,Generator loss:3.845882\n",
      "\n",
      "Epoch 325/400, Time: 31.222209453582764, Discriminator loss:0.7804289,Generator loss:3.0356078\n",
      "\n",
      "Epoch 326/400, Time: 27.85986828804016, Discriminator loss:0.8177602,Generator loss:2.8146305\n",
      "\n",
      "Epoch 327/400, Time: 29.46386170387268, Discriminator loss:0.7658278,Generator loss:3.108389\n",
      "\n",
      "Epoch 328/400, Time: 29.873584747314453, Discriminator loss:0.75551176,Generator loss:4.336033\n",
      "\n",
      "Epoch 329/400, Time: 29.79518985748291, Discriminator loss:0.77257633,Generator loss:4.02073\n",
      "\n",
      "Epoch 330/400, Time: 29.75546407699585, Discriminator loss:0.75449824,Generator loss:3.5518746\n",
      "\n",
      "Epoch 331/400, Time: 30.07693648338318, Discriminator loss:0.77311516,Generator loss:3.0134602\n",
      "\n",
      "Epoch 332/400, Time: 29.817569255828857, Discriminator loss:0.738785,Generator loss:2.9296153\n",
      "\n",
      "Epoch 333/400, Time: 26.31046223640442, Discriminator loss:0.76641816,Generator loss:4.123319\n",
      "\n",
      "Epoch 334/400, Time: 26.256754159927368, Discriminator loss:0.81442314,Generator loss:3.5190787\n",
      "\n",
      "Epoch 335/400, Time: 28.170573234558105, Discriminator loss:0.76663697,Generator loss:3.703283\n",
      "\n",
      "Epoch 336/400, Time: 30.35714340209961, Discriminator loss:0.89705926,Generator loss:3.9560585\n",
      "\n",
      "Epoch 337/400, Time: 28.758485317230225, Discriminator loss:0.8253268,Generator loss:3.0058644\n",
      "\n",
      "Epoch 338/400, Time: 28.905791997909546, Discriminator loss:0.77567124,Generator loss:2.7061749\n",
      "\n",
      "Epoch 339/400, Time: 30.125718355178833, Discriminator loss:0.7773999,Generator loss:4.7663746\n",
      "\n",
      "Epoch 340/400, Time: 29.179131984710693, Discriminator loss:0.80436015,Generator loss:4.1086855\n",
      "\n",
      "Epoch 341/400, Time: 30.786662578582764, Discriminator loss:0.8717696,Generator loss:2.1683295\n",
      "\n",
      "Epoch 342/400, Time: 27.301477909088135, Discriminator loss:0.7702938,Generator loss:3.5638442\n",
      "\n",
      "Epoch 343/400, Time: 27.954151153564453, Discriminator loss:0.9705606,Generator loss:3.1630445\n",
      "\n",
      "Epoch 344/400, Time: 31.52988624572754, Discriminator loss:0.75866574,Generator loss:3.893456\n",
      "\n",
      "Epoch 345/400, Time: 28.830929040908813, Discriminator loss:0.7840891,Generator loss:4.4433727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 346/400, Time: 30.857418298721313, Discriminator loss:0.7641773,Generator loss:3.9036427\n",
      "\n",
      "Epoch 347/400, Time: 29.073664903640747, Discriminator loss:0.7959327,Generator loss:3.301043\n",
      "\n",
      "Epoch 348/400, Time: 30.63842272758484, Discriminator loss:0.7700819,Generator loss:3.106958\n",
      "\n",
      "Epoch 349/400, Time: 29.31922674179077, Discriminator loss:0.7731363,Generator loss:3.1892605\n",
      "\n",
      "Epoch 350/400, Time: 26.236090183258057, Discriminator loss:0.74015427,Generator loss:3.9940917\n",
      "\n",
      "Epoch 351/400, Time: 27.108957767486572, Discriminator loss:0.79127276,Generator loss:3.3146486\n",
      "\n",
      "Epoch 352/400, Time: 30.260005950927734, Discriminator loss:0.7679405,Generator loss:3.6783974\n",
      "\n",
      "Epoch 353/400, Time: 29.442238807678223, Discriminator loss:0.76468176,Generator loss:3.972277\n",
      "\n",
      "Epoch 354/400, Time: 30.34156322479248, Discriminator loss:0.73401463,Generator loss:3.4628246\n",
      "\n",
      "Epoch 355/400, Time: 30.380213499069214, Discriminator loss:0.7633462,Generator loss:3.3763165\n",
      "\n",
      "Epoch 356/400, Time: 29.582578659057617, Discriminator loss:0.8479678,Generator loss:2.9321687\n",
      "\n",
      "Epoch 357/400, Time: 29.7129168510437, Discriminator loss:0.75818497,Generator loss:3.9158425\n",
      "\n",
      "Epoch 358/400, Time: 27.120517253875732, Discriminator loss:0.7538681,Generator loss:2.7660365\n",
      "\n",
      "Epoch 359/400, Time: 26.43583345413208, Discriminator loss:0.786395,Generator loss:3.7408602\n",
      "\n",
      "Epoch 360/400, Time: 30.398520469665527, Discriminator loss:0.75920236,Generator loss:3.6655693\n",
      "\n",
      "Epoch 361/400, Time: 30.216716051101685, Discriminator loss:0.93143356,Generator loss:3.2973063\n",
      "\n",
      "Epoch 362/400, Time: 29.418428659439087, Discriminator loss:0.7887528,Generator loss:3.5568018\n",
      "\n",
      "Epoch 363/400, Time: 29.860352993011475, Discriminator loss:0.78483605,Generator loss:3.7345288\n",
      "\n",
      "Epoch 364/400, Time: 29.08648419380188, Discriminator loss:0.74776095,Generator loss:3.7749767\n",
      "\n",
      "Epoch 365/400, Time: 30.847602367401123, Discriminator loss:0.75398433,Generator loss:3.2496634\n",
      "\n",
      "Epoch 366/400, Time: 28.955234050750732, Discriminator loss:0.76176083,Generator loss:3.3247967\n",
      "\n",
      "Epoch 367/400, Time: 26.9807870388031, Discriminator loss:0.7477293,Generator loss:3.0011516\n",
      "\n",
      "Epoch 368/400, Time: 29.365528345108032, Discriminator loss:0.8374165,Generator loss:2.194942\n",
      "\n",
      "Epoch 369/400, Time: 30.76332974433899, Discriminator loss:0.7746355,Generator loss:3.0509782\n",
      "\n",
      "Epoch 370/400, Time: 28.581552505493164, Discriminator loss:0.7363496,Generator loss:2.5144973\n",
      "\n",
      "Epoch 371/400, Time: 31.010870218276978, Discriminator loss:0.77312833,Generator loss:3.263121\n",
      "\n",
      "Epoch 372/400, Time: 29.567094087600708, Discriminator loss:0.74281394,Generator loss:3.2552104\n",
      "\n",
      "Epoch 373/400, Time: 31.524983406066895, Discriminator loss:0.8009553,Generator loss:3.6905277\n",
      "\n",
      "Epoch 374/400, Time: 29.664862394332886, Discriminator loss:0.809275,Generator loss:4.1369314\n",
      "\n",
      "Epoch 375/400, Time: 26.245748281478882, Discriminator loss:0.7456302,Generator loss:2.7803771\n",
      "\n",
      "Epoch 376/400, Time: 28.026826858520508, Discriminator loss:0.7784555,Generator loss:4.0898914\n",
      "\n",
      "Epoch 377/400, Time: 30.881648063659668, Discriminator loss:0.76343507,Generator loss:3.7849102\n",
      "\n",
      "Epoch 378/400, Time: 29.19074010848999, Discriminator loss:0.8510569,Generator loss:3.1413846\n",
      "\n",
      "Epoch 379/400, Time: 31.41036343574524, Discriminator loss:0.77894586,Generator loss:2.908414\n",
      "\n",
      "Epoch 380/400, Time: 29.752445459365845, Discriminator loss:0.75389826,Generator loss:3.5521011\n",
      "\n",
      "Epoch 381/400, Time: 30.888926029205322, Discriminator loss:0.76189023,Generator loss:3.7205865\n",
      "\n",
      "Epoch 382/400, Time: 29.753219604492188, Discriminator loss:0.743204,Generator loss:3.4644928\n",
      "\n",
      "Epoch 383/400, Time: 26.967998027801514, Discriminator loss:0.7645619,Generator loss:4.5534124\n",
      "\n",
      "Epoch 384/400, Time: 26.984554529190063, Discriminator loss:0.84433013,Generator loss:4.0058966\n",
      "\n",
      "Epoch 385/400, Time: 31.259577989578247, Discriminator loss:0.7987376,Generator loss:2.929854\n",
      "\n",
      "Epoch 386/400, Time: 30.35372829437256, Discriminator loss:0.84153867,Generator loss:3.4259667\n",
      "\n",
      "Epoch 387/400, Time: 31.231930255889893, Discriminator loss:0.7749964,Generator loss:3.1099417\n",
      "\n",
      "Epoch 388/400, Time: 30.501121997833252, Discriminator loss:0.80316544,Generator loss:2.9782891\n",
      "\n",
      "Epoch 389/400, Time: 30.59922695159912, Discriminator loss:0.76507753,Generator loss:3.1250718\n",
      "\n",
      "Epoch 390/400, Time: 30.95401954650879, Discriminator loss:0.75982505,Generator loss:3.3721287\n",
      "\n",
      "Epoch 391/400, Time: 27.193801403045654, Discriminator loss:0.7896137,Generator loss:4.197788\n",
      "\n",
      "Epoch 392/400, Time: 27.219541549682617, Discriminator loss:0.75220346,Generator loss:3.6465676\n",
      "\n",
      "Epoch 393/400, Time: 30.73884892463684, Discriminator loss:0.7854942,Generator loss:3.8433063\n",
      "\n",
      "Epoch 394/400, Time: 30.47466540336609, Discriminator loss:0.8199371,Generator loss:2.8634412\n",
      "\n",
      "Epoch 395/400, Time: 30.14708399772644, Discriminator loss:0.8513395,Generator loss:3.6890736\n",
      "\n",
      "Epoch 396/400, Time: 30.298815727233887, Discriminator loss:0.76382357,Generator loss:3.4312901\n",
      "\n",
      "Epoch 397/400, Time: 29.004027605056763, Discriminator loss:0.75098467,Generator loss:3.7081733\n",
      "\n",
      "Epoch 398/400, Time: 31.424150943756104, Discriminator loss:0.74875504,Generator loss:3.963531\n",
      "\n",
      "Epoch 399/400, Time: 29.442222118377686, Discriminator loss:0.7823664,Generator loss:3.1715617\n",
      "\n",
      "Epoch 400/400, Time: 26.624581575393677, Discriminator loss:0.970019,Generator loss:3.1303272\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" #Set backend to tensorflow\n",
    "image_data_format = \"channels_last\" #Setting image data format for tensorflow\n",
    "K.set_image_data_format(image_data_format)    \n",
    "# Launch training\n",
    "train_GAN(batch_size,n_batch_per_epoch,nb_epoch,generator,model_name,image_data_format,img_dim,bn_mode,label_smoothing,label_flipping,noise_scale,dset,use_mbd,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jMArMNyOUfz0"
   },
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "GAN_CelebFaceA.ipynb",
   "provenance": [
    {
     "file_id": "1OeNzGPshHmF_jwN1lv5BYX0HJNTV5AjE",
     "timestamp": 1528645865817
    },
    {
     "file_id": "https://github.com/siddharthalodha/mlsid/blob/master/GAN_CelebFaceA.ipynb",
     "timestamp": 1528627132682
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
