{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_CelebFaceA_17jun.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1OeNzGPshHmF_jwN1lv5BYX0HJNTV5AjE",
          "timestamp": 1528645865817
        },
        {
          "file_id": "https://github.com/siddharthalodha/mlsid/blob/master/GAN_CelebFaceA.ipynb",
          "timestamp": 1528627132682
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3cLJSP8tdJf7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Source : https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/GAN \n",
        "# Project Title : Convert GAN implementation into IPython Notebook\n",
        "\n",
        "# Current Progress\n",
        "# 1. Convert main model,training files\n",
        "# 2. Create HDF5 dataset to be used for training\n",
        "# 3. Trained network on CelebA dataset for 400 epochs\n",
        "# 4. Improve implementation to generate better quality images using other GAN implementations like BEGAN, PGGAN etc.\n",
        "# 5. Add descriptions in code (WIP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvRwO4lXb43a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/siddharthalodha/DCGAN_KERAS.git\n",
        "!cp -r DCGAN_KERAS/models .\n",
        "!cp -r DCGAN_KERAS/figures .\n",
        "!cp -r DCGAN_KERAS/utils .  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hH5ebnAGSCyE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Code to download CelebA hdf5 dataset from google drive\n",
        "!pip install PyDrive\n",
        "\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileId = drive.CreateFile({'id': '1cUBPxqU-9Y6f_OAfPwdRmPg7ruZ2sfdk'})\n",
        "print(fileId['title'])  # CelebA Dataset\n",
        "fileId.GetContentFile('CelebA_64_data.h5')  # Save Drive file as a local file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PHzXF_Pua7-o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e7650ed3-6efc-4e32-9808-2d0674160012",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529240977017,
          "user_tz": -330,
          "elapsed": 6406,
          "user": {
            "displayName": "Siddhartha Lodha",
            "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
            "userId": "117940677094137339921"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "#Fixing graphviz pydot installation for plot_model function to work\n",
        "!sudo apt-get install graphviz\n",
        "!pip install pydot\n",
        "!pip install graphviz\n",
        "!pip install graphviz pydot\n",
        "\n",
        "import graphviz\n",
        "import pydot\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matplotlib.style.use('ggplot')\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.8.3)\r\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.2.4)\r\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.2.0)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TsO9WacsQbMC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Deconv2D, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers import Input, Concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from keras.utils import generic_utils\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.generic_utils import Progbar\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "sys.path.append(\"./utils\") # Utils\n",
        "import general_utils\n",
        "import data_utils #Being used for importing data,generating batches (CelebA Data is currently stored in an hdf5 file)\n",
        "%matplotlib inline\n",
        "\n",
        "#!mkdir /figures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ExF9V5Qwdai-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "\n",
        "backend=\"tensorflow\" #Specify backend to be used\n",
        "dset=\"celebA\" #Specify dataset to be used, currently supported : mnist/celebA\n",
        "generator=\"upsampling\" #Generator to be used : upsampling/deconv\n",
        "model_name=\"CNN\" #Name of model\n",
        "batch_size=32 #Batch size to be used \n",
        "n_batch_per_epoch=200 #Number of batches per epoch\n",
        "nb_epoch=400 #Number of epochs\n",
        "epoch=10 #Epoch size => Used for progress bars \n",
        "nb_classes=2 #Number of classes\n",
        "do_plot=True #Plotting during execution\n",
        "bn_mode=2 #Batch normalization\n",
        "img_dim=64 #Dimension of image\n",
        "label_smoothing=\"store_true\" #Label smoothing\n",
        "label_flipping=0 #Label flipping\n",
        "noise_scale=0.5 \n",
        "use_mbd=\"store_true\"\n",
        "image_data_format = \"channels_last\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOI0MRTxa7-0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Downloading CelebA hdf5 dataset if not already downloaded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ElbiB72ccM4Y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60509087-dd1d-417f-a89b-5cdbbc3a0054",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529240981318,
          "user_tz": -330,
          "elapsed": 1417,
          "user": {
            "displayName": "Siddhartha Lodha",
            "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
            "userId": "117940677094137339921"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "      raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "K.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SAkCVJWIa7_A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define generator function#1 : Upsampling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "luzh9Wm2ccMp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def generator_upsampling(noise_dim, img_dim, bn_mode, model_name=\"generator_upsampling\", dset=\"celebA\"):\n",
        "    \"\"\"\n",
        "    Generator model of the DCGAN\n",
        "    args : img_dim (tuple of int) num_chan, height, width\n",
        "           pretr_weights_file (str) file holding pre trained weights\n",
        "    returns : model (keras NN) the Neural Net model\n",
        "    \"\"\"\n",
        "\n",
        "    s = img_dim[1]\n",
        "    f = 512\n",
        "\n",
        "    if dset == \"mnist\":\n",
        "        start_dim = int(s / 4)\n",
        "        nb_upconv = 2\n",
        "    else:\n",
        "        start_dim = int(s / 16)\n",
        "        nb_upconv = 4\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        bn_axis = 1\n",
        "        reshape_shape = (f, start_dim, start_dim)\n",
        "        output_channels = img_dim[0]\n",
        "    else:\n",
        "        reshape_shape = (start_dim, start_dim, f)\n",
        "        bn_axis = -1\n",
        "        output_channels = img_dim[-1]\n",
        "\n",
        "    gen_input = Input(shape=noise_dim, name=\"generator_input\")\n",
        "\n",
        "    x = Dense(f * start_dim * start_dim, input_dim=noise_dim)(gen_input)\n",
        "    x = Reshape(reshape_shape)(x)\n",
        "    x = BatchNormalization(axis=bn_axis)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Upscaling blocks\n",
        "    for i in range(nb_upconv):\n",
        "        x = UpSampling2D(size=(2, 2))(x)\n",
        "        nb_filters = int(f / (2 ** (i + 1)))\n",
        "        x = Conv2D(nb_filters, (3, 3), padding=\"same\")(x)\n",
        "        x = BatchNormalization(axis=1)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2D(nb_filters, (3, 3), padding=\"same\")(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(output_channels, (3, 3), name=\"gen_Conv2D_final\", padding=\"same\", activation='tanh')(x)\n",
        "\n",
        "    generator_model = Model(inputs=[gen_input], outputs=[x], name=model_name)\n",
        "\n",
        "    return generator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C6LGba6ea7_G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define generator function#2 : Deconvolution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7E3w4MFa7_I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def generator_deconv(noise_dim, img_dim, bn_mode, batch_size, model_name=\"generator_deconv\", dset=\"mnist\"):\n",
        "    \"\"\"\n",
        "    Generator model of the DCGAN\n",
        "    args : nb_classes (int) number of classes\n",
        "           img_dim (tuple of int) num_chan, height, width\n",
        "           pretr_weights_file (str) file holding pre trained weights\n",
        "    returns : model (keras NN) the Neural Net model\n",
        "    \"\"\"\n",
        "\n",
        "    assert K.backend() == \"tensorflow\", \"Deconv not implemented with theano\"\n",
        "\n",
        "    s = img_dim[1]\n",
        "    f = 512\n",
        "\n",
        "    if dset == \"mnist\":\n",
        "        start_dim = int(s / 4)\n",
        "        nb_upconv = 2\n",
        "    else:\n",
        "        start_dim = int(s / 16)\n",
        "        nb_upconv = 4\n",
        "\n",
        "    reshape_shape = (start_dim, start_dim, f)\n",
        "    bn_axis = -1\n",
        "    output_channels = img_dim[-1]\n",
        "\n",
        "    gen_input = Input(shape=noise_dim, name=\"generator_input\")\n",
        "\n",
        "    x = Dense(f * start_dim * start_dim, input_dim=noise_dim)(gen_input)\n",
        "    x = Reshape(reshape_shape)(x)\n",
        "    x = BatchNormalization(axis=bn_axis)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Transposed conv blocks\n",
        "    for i in range(nb_upconv - 1):\n",
        "        nb_filters = int(f / (2 ** (i + 1)))\n",
        "        s = start_dim * (2 ** (i + 1))\n",
        "        o_shape = (batch_size, s, s, nb_filters)\n",
        "        x = Deconv2D(nb_filters, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
        "        x = BatchNormalization(axis=-1)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Last block\n",
        "    s = start_dim * (2 ** (nb_upconv))\n",
        "    o_shape = (batch_size, s, s, output_channels)\n",
        "    x = Deconv2D(output_channels, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
        "    x = Activation(\"tanh\")(x)\n",
        "\n",
        "    generator_model = Model(inputs=[gen_input], outputs=[x], name=model_name)\n",
        "\n",
        "    return generator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5r0xTKLha7_N",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define DCGAN model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_tA4upbqa7_Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def DCGAN(generator, discriminator_model, noise_dim, img_dim):\n",
        "\n",
        "    noise_input = Input(shape=noise_dim, name=\"noise_input\")\n",
        "\n",
        "    generated_image = generator(noise_input)\n",
        "    DCGAN_output = discriminator_model(generated_image)\n",
        "\n",
        "    DCGAN = Model(inputs=[noise_input],\n",
        "                  outputs=[DCGAN_output],\n",
        "                  name=\"DCGAN\")\n",
        "    return DCGAN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2V9CMisa7_T",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define loader function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QqZdwU2ta7_W",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def load(model_name, noise_dim, img_dim, bn_mode, batch_size, dset=\"mnist\", use_mbd=False):\n",
        "\n",
        "    if model_name == \"generator_upsampling\":\n",
        "        model = generator_upsampling(noise_dim, img_dim, bn_mode, model_name=model_name, dset=dset)\n",
        "        model.summary()\n",
        "        #plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
        "        return model\n",
        "    if model_name == \"generator_deconv\":\n",
        "        model = generator_deconv(noise_dim, img_dim, bn_mode, batch_size, model_name=model_name, dset=dset)\n",
        "        model.summary()\n",
        "        #plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
        "        return model\n",
        "    if model_name == \"DCGAN_discriminator\":\n",
        "        model = DCGAN_discriminator(noise_dim, img_dim, bn_mode, model_name=model_name, dset=dset, use_mbd=use_mbd)\n",
        "        model.summary()\n",
        "        #plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jppSHWXFa7_Y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Define discriminator function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVGxtwbHa7_b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def DCGAN_discriminator(noise_dim, img_dim, bn_mode, model_name=\"DCGAN_discriminator\", dset=\"celebA\", use_mbd=False):\n",
        "    \"\"\"\n",
        "    Discriminator model of the DCGAN\n",
        "    args : img_dim (tuple of int) num_chan, height, width\n",
        "           pretr_weights_file (str) file holding pre trained weights\n",
        "    returns : model (keras NN) the Neural Net model\n",
        "    \"\"\"\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        bn_axis = 1\n",
        "    else:\n",
        "        bn_axis = -1\n",
        "\n",
        "    disc_input = Input(shape=img_dim, name=\"discriminator_input\")\n",
        "\n",
        "    if dset == \"mnist\":\n",
        "        list_f = [128]\n",
        "\n",
        "    else:\n",
        "        list_f = [64, 128, 256]\n",
        "\n",
        "    # First conv\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), name=\"disc_Conv2D_1\", padding=\"same\")(disc_input)\n",
        "    x = BatchNormalization(axis=bn_axis)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    # Next convs\n",
        "    for i, f in enumerate(list_f):\n",
        "        name = \"disc_Conv2D_%s\" % (i + 2)\n",
        "        x = Conv2D(f, (3, 3), strides=(2, 2), name=name, padding=\"same\")(x)\n",
        "        x = BatchNormalization(axis=bn_axis)(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    def minb_disc(x):\n",
        "        diffs = K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, [1, 2, 0]), 0)\n",
        "        abs_diffs = K.sum(K.abs(diffs), 2)\n",
        "        x = K.sum(K.exp(-abs_diffs), 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def lambda_output(input_shape):\n",
        "        return input_shape[:2]\n",
        "\n",
        "    num_kernels = 100\n",
        "    dim_per_kernel = 5\n",
        "\n",
        "    M = Dense(num_kernels * dim_per_kernel, use_bias=False, activation=None)\n",
        "    MBD = Lambda(minb_disc, output_shape=lambda_output)\n",
        "\n",
        "    if use_mbd:\n",
        "        x_mbd = M(x)\n",
        "        x_mbd = Reshape((num_kernels, dim_per_kernel))(x_mbd)\n",
        "        x_mbd = MBD(x_mbd)\n",
        "        x = Concatenate(axis=bn_axis)([x, x_mbd])\n",
        "\n",
        "    x = Dense(2, activation='softmax', name=\"disc_dense_2\")(x)\n",
        "\n",
        "    discriminator_model = Model(inputs=[disc_input], outputs=[x], name=model_name)\n",
        "\n",
        "    return discriminator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JYvIBjcLcg_F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train_GAN(batch_size,n_batch_per_epoch,nb_epoch,generator,model_name,image_data_format,img_dim,bn_mode,label_smoothing,label_flipping,noise_scale,dset,use_mbd,epoch_size):\n",
        "    # Setup environment (logging directory etc)\n",
        "    general_utils.setup_logging(model_name)\n",
        "\n",
        "    # Load and rescale data\n",
        "    if dset == \"celebA\":\n",
        "        X_real_train = data_utils.load_celebA(img_dim, image_data_format) #change func call if file moved\n",
        "    if dset == \"mnist\":\n",
        "        X_real_train, _, _, _ = data_utils.load_mnist(image_data_format) #change func call if file moved\n",
        "    img_dim = X_real_train.shape[-3:]\n",
        "    noise_dim = (100,)\n",
        "    \n",
        "    try:\n",
        "\n",
        "        # Create optimizers\n",
        "        opt_dcgan = Adam(lr=2E-4, beta_1=0.5, beta_2=0.999, epsilon=1e-08)\n",
        "        opt_discriminator = SGD(lr=1E-3, momentum=0.9, nesterov=True)\n",
        "\n",
        "        # Load generator model\n",
        "        generator_model = load(\"generator_%s\" % generator,\n",
        "                                      noise_dim,\n",
        "                                      img_dim,\n",
        "                                      bn_mode,\n",
        "                                      batch_size,\n",
        "                                      dset=dset,\n",
        "                                      use_mbd=use_mbd)\n",
        "        \n",
        "        # Load discriminator model\n",
        "        discriminator_model = load(\"DCGAN_discriminator\",\n",
        "                                          noise_dim,\n",
        "                                          img_dim,\n",
        "                                          bn_mode,\n",
        "                                          batch_size,\n",
        "                                          dset=dset,\n",
        "                                          use_mbd=use_mbd)\n",
        "\n",
        "        generator_model.compile(loss='mse', optimizer=opt_discriminator)\n",
        "        discriminator_model.trainable = False\n",
        "        DCGAN_model = DCGAN(generator_model,\n",
        "                                   discriminator_model,\n",
        "                                   noise_dim,\n",
        "                                   img_dim)\n",
        "        \n",
        "        loss = ['binary_crossentropy']\n",
        "        loss_weights = [1]\n",
        "        DCGAN_model.compile(loss=loss, loss_weights=loss_weights, optimizer=opt_dcgan)\n",
        "\n",
        "        discriminator_model.trainable = True\n",
        "        discriminator_model.compile(loss='binary_crossentropy', optimizer=opt_discriminator)\n",
        "\n",
        "        gen_loss = 100\n",
        "        disc_loss = 100\n",
        "\n",
        "        # Start training\n",
        "        print(\"Start training\")\n",
        "        for e in range(nb_epoch):\n",
        "            #Initialize progbar and batch counter\n",
        "            #progbar = Progbar(epoch_size)\n",
        "            batch_counter = 1\n",
        "            start = time.time()\n",
        "            for X_real_batch in data_utils.gen_batch(X_real_train, batch_size):\n",
        "\n",
        "                # Create a batch to feed the discriminator model\n",
        "                X_disc, y_disc = data_utils.get_disc_batch(X_real_batch,\n",
        "                                                           generator_model,\n",
        "                                                           batch_counter,\n",
        "                                                           batch_size,\n",
        "                                                           noise_dim,\n",
        "                                                           noise_scale=noise_scale,\n",
        "                                                           label_smoothing=label_smoothing,\n",
        "                                                           label_flipping=label_flipping)\n",
        "\n",
        "                # Update the discriminator\n",
        "                disc_loss = discriminator_model.train_on_batch(X_disc, y_disc)\n",
        "\n",
        "                # Create a batch to feed the generator model\n",
        "                X_gen, y_gen = data_utils.get_gen_batch(batch_size, noise_dim, noise_scale=noise_scale)\n",
        "\n",
        "                # Freeze the discriminator\n",
        "                discriminator_model.trainable = False\n",
        "                gen_loss = DCGAN_model.train_on_batch(X_gen, y_gen)\n",
        "                # Unfreeze the discriminator\n",
        "                discriminator_model.trainable = True\n",
        "\n",
        "                batch_counter += 1\n",
        "                #progbar.add(batch_size, values=[(\"D logloss\", disc_loss),\n",
        "                #                                (\"G logloss\", gen_loss)])\n",
        "\n",
        "                 #Save images for visualization\n",
        "                if batch_counter % 100 == 0:\n",
        "                    data_utils.plot_generated_batch(X_real_batch, generator_model,\n",
        "                                                    batch_size, noise_dim, image_data_format)\n",
        "                    \n",
        "                if batch_counter >= n_batch_per_epoch:\n",
        "                    break\n",
        "\n",
        "            print(\"\")\n",
        "            print('Epoch %s/%s, Time: %s, Discriminator loss:%s,Generator loss:%s' % (e + 1, nb_epoch, time.time() - start,disc_loss,gen_loss))\n",
        "\n",
        "            #Save weights for generator,discriminator and DCGAN\n",
        "            if e % 5 == 0:\n",
        "                gen_weights_path = os.path.join('./models/%s/gen_weights_epoch%s.h5' % (model_name, e))\n",
        "                generator_model.save_weights(gen_weights_path, overwrite=True)\n",
        "\n",
        "                disc_weights_path = os.path.join('./models/%s/disc_weights_epoch%s.h5' % (model_name, e))\n",
        "                discriminator_model.save_weights(disc_weights_path, overwrite=True)\n",
        "\n",
        "                DCGAN_weights_path = os.path.join('./models/%s/DCGAN_weights_epoch%s.h5' % (model_name, e))\n",
        "                DCGAN_model.save_weights(DCGAN_weights_path, overwrite=True)\n",
        "    except Exception as e:\n",
        "            print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNolsYjGcsAH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 5627
        },
        "outputId": "5685889a-203c-4c6f-9646-7216dd5b6296"
      },
      "cell_type": "code",
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" #Set backend to tensorflow\n",
        "image_data_format = \"channels_last\" #Setting image data format for tensorflow\n",
        "K.set_image_data_format(image_data_format)    \n",
        "# Launch training\n",
        "train_GAN(batch_size,n_batch_per_epoch,nb_epoch,generator,model_name,image_data_format,img_dim,bn_mode,label_smoothing,label_flipping,noise_scale,dset,use_mbd,epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "generator_input (InputLayer) (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8192)              827392    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 256)         1179904   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 256)         32        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 128)       295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 128)       64        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 64)        128       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 64, 64, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64, 64, 32)        256       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 64, 64, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "gen_Conv2D_final (Conv2D)    (None, 64, 64, 3)         867       \n",
            "=================================================================\n",
            "Total params: 3,181,827\n",
            "Trainable params: 3,180,563\n",
            "Non-trainable params: 1,264\n",
            "_________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "discriminator_input (InputLayer (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "disc_Conv2D_1 (Conv2D)          (None, 32, 32, 32)   896         discriminator_input[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         disc_Conv2D_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "disc_Conv2D_2 (Conv2D)          (None, 16, 16, 64)   18496       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   256         disc_Conv2D_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "disc_Conv2D_3 (Conv2D)          (None, 8, 8, 128)    73856       leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 128)    512         disc_Conv2D_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 8, 8, 128)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "disc_Conv2D_4 (Conv2D)          (None, 4, 4, 256)    295168      leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 4, 4, 256)    1024        disc_Conv2D_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 4, 4, 256)    0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4096)         0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 500)          2048000     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 100, 5)       0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 100)          0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4196)         0           flatten_1[0][0]                  \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "disc_dense_2 (Dense)            (None, 2)            8394        concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,446,730\n",
            "Trainable params: 2,445,770\n",
            "Non-trainable params: 960\n",
            "__________________________________________________________________________________________________\n",
            "Start training\n",
            "\n",
            "Epoch 1/400, Time: 32.667892932891846, Discriminator loss:1.0870671,Generator loss:2.5044913\n",
            "\n",
            "Epoch 2/400, Time: 25.326797485351562, Discriminator loss:0.89183474,Generator loss:1.9392967\n",
            "\n",
            "Epoch 3/400, Time: 25.314013719558716, Discriminator loss:0.8825084,Generator loss:2.2441196\n",
            "\n",
            "Epoch 4/400, Time: 25.366274118423462, Discriminator loss:0.84531873,Generator loss:3.5196624\n",
            "\n",
            "Epoch 5/400, Time: 25.297727823257446, Discriminator loss:0.78197324,Generator loss:2.4997902\n",
            "\n",
            "Epoch 6/400, Time: 25.373528242111206, Discriminator loss:0.94545233,Generator loss:2.626942\n",
            "\n",
            "Epoch 7/400, Time: 25.37070870399475, Discriminator loss:0.92086035,Generator loss:3.07801\n",
            "\n",
            "Epoch 8/400, Time: 25.374232053756714, Discriminator loss:0.8781699,Generator loss:2.5013757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9/400, Time: 25.370331287384033, Discriminator loss:0.8296232,Generator loss:2.5896418\n",
            "\n",
            "Epoch 10/400, Time: 25.388696908950806, Discriminator loss:0.7978655,Generator loss:3.914293\n",
            "\n",
            "Epoch 11/400, Time: 25.330079078674316, Discriminator loss:0.779403,Generator loss:3.4272146\n",
            "\n",
            "Epoch 12/400, Time: 25.408722400665283, Discriminator loss:0.81829184,Generator loss:1.8667287\n",
            "\n",
            "Epoch 13/400, Time: 25.42686438560486, Discriminator loss:0.81638074,Generator loss:3.0628858\n",
            "\n",
            "Epoch 14/400, Time: 25.435884475708008, Discriminator loss:0.8598822,Generator loss:3.4370396\n",
            "\n",
            "Epoch 15/400, Time: 25.463157653808594, Discriminator loss:0.79648024,Generator loss:3.6076522\n",
            "\n",
            "Epoch 16/400, Time: 25.44814157485962, Discriminator loss:0.7528094,Generator loss:3.0966368\n",
            "\n",
            "Epoch 17/400, Time: 25.30066990852356, Discriminator loss:0.84079754,Generator loss:3.383903\n",
            "\n",
            "Epoch 18/400, Time: 25.36725664138794, Discriminator loss:0.8263195,Generator loss:2.5336032\n",
            "\n",
            "Epoch 19/400, Time: 25.443798780441284, Discriminator loss:0.79852355,Generator loss:2.9358878\n",
            "\n",
            "Epoch 20/400, Time: 25.489850997924805, Discriminator loss:0.7676116,Generator loss:3.8662539\n",
            "\n",
            "Epoch 21/400, Time: 25.453073740005493, Discriminator loss:0.7939105,Generator loss:2.6738615\n",
            "\n",
            "Epoch 22/400, Time: 25.449798583984375, Discriminator loss:0.7940383,Generator loss:2.9440453\n",
            "\n",
            "Epoch 23/400, Time: 25.42295742034912, Discriminator loss:1.0146288,Generator loss:1.9475429\n",
            "\n",
            "Epoch 24/400, Time: 25.52887272834778, Discriminator loss:0.8226395,Generator loss:2.6130483\n",
            "\n",
            "Epoch 25/400, Time: 25.540990829467773, Discriminator loss:0.7765789,Generator loss:2.8086724\n",
            "\n",
            "Epoch 26/400, Time: 25.549638986587524, Discriminator loss:0.9052602,Generator loss:3.2028847\n",
            "\n",
            "Epoch 27/400, Time: 25.53989553451538, Discriminator loss:0.7590469,Generator loss:3.3122609\n",
            "\n",
            "Epoch 28/400, Time: 25.54408621788025, Discriminator loss:0.8120319,Generator loss:3.203967\n",
            "\n",
            "Epoch 29/400, Time: 25.5826416015625, Discriminator loss:0.76645124,Generator loss:2.9845371\n",
            "\n",
            "Epoch 30/400, Time: 25.652499437332153, Discriminator loss:0.74731636,Generator loss:3.1061091\n",
            "\n",
            "Epoch 31/400, Time: 25.64639186859131, Discriminator loss:0.84640115,Generator loss:3.3244681\n",
            "\n",
            "Epoch 32/400, Time: 25.62619709968567, Discriminator loss:0.81849873,Generator loss:3.425749\n",
            "\n",
            "Epoch 33/400, Time: 25.683454275131226, Discriminator loss:0.79067,Generator loss:3.7643065\n",
            "\n",
            "Epoch 34/400, Time: 25.601755619049072, Discriminator loss:0.7276367,Generator loss:4.0567684\n",
            "\n",
            "Epoch 35/400, Time: 25.519129991531372, Discriminator loss:0.79106176,Generator loss:2.7313912\n",
            "\n",
            "Epoch 36/400, Time: 25.575409412384033, Discriminator loss:0.90347946,Generator loss:3.9438558\n",
            "\n",
            "Epoch 37/400, Time: 25.59145951271057, Discriminator loss:0.76766974,Generator loss:3.3750005\n",
            "\n",
            "Epoch 38/400, Time: 25.547803163528442, Discriminator loss:0.75905347,Generator loss:3.18028\n",
            "\n",
            "Epoch 39/400, Time: 25.601685047149658, Discriminator loss:0.7464148,Generator loss:4.346664\n",
            "\n",
            "Epoch 40/400, Time: 25.534603357315063, Discriminator loss:0.8430929,Generator loss:3.8949423\n",
            "\n",
            "Epoch 41/400, Time: 25.51759672164917, Discriminator loss:0.89017415,Generator loss:3.5460944\n",
            "\n",
            "Epoch 42/400, Time: 25.47408366203308, Discriminator loss:0.7784083,Generator loss:3.883929\n",
            "\n",
            "Epoch 43/400, Time: 25.529985189437866, Discriminator loss:0.7903044,Generator loss:3.252049\n",
            "\n",
            "Epoch 44/400, Time: 25.628698348999023, Discriminator loss:0.8172418,Generator loss:3.2058659\n",
            "\n",
            "Epoch 45/400, Time: 25.679622411727905, Discriminator loss:0.7676638,Generator loss:3.633308\n",
            "\n",
            "Epoch 46/400, Time: 25.69895577430725, Discriminator loss:0.8029779,Generator loss:2.965838\n",
            "\n",
            "Epoch 47/400, Time: 25.6597158908844, Discriminator loss:0.7467948,Generator loss:3.3042107\n",
            "\n",
            "Epoch 48/400, Time: 25.691479444503784, Discriminator loss:0.77114743,Generator loss:4.02124\n",
            "\n",
            "Epoch 49/400, Time: 25.684539556503296, Discriminator loss:0.8349213,Generator loss:2.9584987\n",
            "\n",
            "Epoch 50/400, Time: 25.620482683181763, Discriminator loss:0.7456491,Generator loss:3.853087\n",
            "\n",
            "Epoch 51/400, Time: 25.639834880828857, Discriminator loss:0.7259121,Generator loss:3.79839\n",
            "\n",
            "Epoch 52/400, Time: 25.687658071517944, Discriminator loss:0.75020516,Generator loss:2.9013724\n",
            "\n",
            "Epoch 53/400, Time: 25.666438341140747, Discriminator loss:0.7578008,Generator loss:3.4021368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 54/400, Time: 25.644271850585938, Discriminator loss:0.7763419,Generator loss:4.458169\n",
            "\n",
            "Epoch 55/400, Time: 25.585081338882446, Discriminator loss:0.76382023,Generator loss:3.3174567\n",
            "\n",
            "Epoch 56/400, Time: 25.627663612365723, Discriminator loss:0.74448776,Generator loss:5.1729198\n",
            "\n",
            "Epoch 57/400, Time: 25.61154580116272, Discriminator loss:0.892535,Generator loss:4.484932\n",
            "\n",
            "Epoch 58/400, Time: 25.582062482833862, Discriminator loss:0.75692654,Generator loss:3.4598339\n",
            "\n",
            "Epoch 59/400, Time: 25.543519258499146, Discriminator loss:0.7860905,Generator loss:4.139801\n",
            "\n",
            "Epoch 60/400, Time: 25.666696310043335, Discriminator loss:0.75770956,Generator loss:4.4770584\n",
            "\n",
            "Epoch 61/400, Time: 25.575538635253906, Discriminator loss:0.7446815,Generator loss:4.3983784\n",
            "\n",
            "Epoch 62/400, Time: 25.638729572296143, Discriminator loss:0.863464,Generator loss:3.4036956\n",
            "\n",
            "Epoch 63/400, Time: 25.64259362220764, Discriminator loss:0.83616817,Generator loss:4.049136\n",
            "\n",
            "Epoch 64/400, Time: 25.58124303817749, Discriminator loss:0.7407206,Generator loss:3.3611615\n",
            "\n",
            "Epoch 65/400, Time: 25.548044443130493, Discriminator loss:0.746282,Generator loss:3.9089613\n",
            "\n",
            "Epoch 66/400, Time: 25.685298681259155, Discriminator loss:0.74157786,Generator loss:3.4603248\n",
            "\n",
            "Epoch 67/400, Time: 25.6116201877594, Discriminator loss:0.7754737,Generator loss:3.62256\n",
            "\n",
            "Epoch 68/400, Time: 25.693232536315918, Discriminator loss:0.7376944,Generator loss:3.413484\n",
            "\n",
            "Epoch 69/400, Time: 25.657780647277832, Discriminator loss:0.7542455,Generator loss:4.8656807\n",
            "\n",
            "Epoch 70/400, Time: 25.628983736038208, Discriminator loss:0.8027543,Generator loss:3.7239609\n",
            "\n",
            "Epoch 71/400, Time: 25.667155981063843, Discriminator loss:0.7998197,Generator loss:3.2689245\n",
            "\n",
            "Epoch 72/400, Time: 25.59476661682129, Discriminator loss:0.8622869,Generator loss:4.3360925\n",
            "\n",
            "Epoch 73/400, Time: 25.62657141685486, Discriminator loss:0.7473697,Generator loss:3.635366\n",
            "\n",
            "Epoch 74/400, Time: 25.575813055038452, Discriminator loss:0.77621615,Generator loss:3.8263168\n",
            "\n",
            "Epoch 75/400, Time: 25.447721242904663, Discriminator loss:0.76893234,Generator loss:4.502166\n",
            "\n",
            "Epoch 76/400, Time: 25.568515300750732, Discriminator loss:0.78095174,Generator loss:4.2032146\n",
            "\n",
            "Epoch 77/400, Time: 25.542668342590332, Discriminator loss:0.8246012,Generator loss:3.734469\n",
            "\n",
            "Epoch 78/400, Time: 25.52469301223755, Discriminator loss:0.74152994,Generator loss:4.105391\n",
            "\n",
            "Epoch 79/400, Time: 25.559213638305664, Discriminator loss:0.7374728,Generator loss:4.7895412\n",
            "\n",
            "Epoch 80/400, Time: 25.568919897079468, Discriminator loss:0.7976495,Generator loss:3.9769306\n",
            "\n",
            "Epoch 81/400, Time: 25.584521293640137, Discriminator loss:0.7428956,Generator loss:4.9885798\n",
            "\n",
            "Epoch 82/400, Time: 25.5309157371521, Discriminator loss:0.7404324,Generator loss:4.0020313\n",
            "\n",
            "Epoch 83/400, Time: 25.57195019721985, Discriminator loss:0.86284184,Generator loss:3.537868\n",
            "\n",
            "Epoch 84/400, Time: 25.558141469955444, Discriminator loss:0.77029175,Generator loss:3.8253505\n",
            "\n",
            "Epoch 85/400, Time: 25.588778018951416, Discriminator loss:0.7196967,Generator loss:4.3149834\n",
            "\n",
            "Epoch 86/400, Time: 25.584516048431396, Discriminator loss:0.7486323,Generator loss:4.2860904\n",
            "\n",
            "Epoch 87/400, Time: 25.519314765930176, Discriminator loss:0.762872,Generator loss:4.627454\n",
            "\n",
            "Epoch 88/400, Time: 25.562703847885132, Discriminator loss:0.74696213,Generator loss:3.8489552\n",
            "\n",
            "Epoch 89/400, Time: 25.537933826446533, Discriminator loss:0.74769807,Generator loss:2.8511906\n",
            "\n",
            "Epoch 90/400, Time: 25.58131194114685, Discriminator loss:1.0300282,Generator loss:3.8211098\n",
            "\n",
            "Epoch 91/400, Time: 25.49322772026062, Discriminator loss:0.78162897,Generator loss:3.8957646\n",
            "\n",
            "Epoch 92/400, Time: 25.57118582725525, Discriminator loss:0.924055,Generator loss:3.737831\n",
            "\n",
            "Epoch 93/400, Time: 25.538583040237427, Discriminator loss:0.7854831,Generator loss:3.2840056\n",
            "\n",
            "Epoch 94/400, Time: 25.562881231307983, Discriminator loss:0.73052907,Generator loss:3.300036\n",
            "\n",
            "Epoch 95/400, Time: 25.536381244659424, Discriminator loss:0.9179562,Generator loss:3.0075169\n",
            "\n",
            "Epoch 96/400, Time: 25.505861043930054, Discriminator loss:0.73633397,Generator loss:4.2527046\n",
            "\n",
            "Epoch 97/400, Time: 25.58493399620056, Discriminator loss:0.72159386,Generator loss:3.3980868\n",
            "\n",
            "Epoch 98/400, Time: 25.483663082122803, Discriminator loss:0.7639074,Generator loss:3.6293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 99/400, Time: 25.543023824691772, Discriminator loss:0.86743844,Generator loss:4.2952785\n",
            "\n",
            "Epoch 100/400, Time: 25.577505350112915, Discriminator loss:0.7469269,Generator loss:3.8945975\n",
            "\n",
            "Epoch 101/400, Time: 25.569599390029907, Discriminator loss:0.73110366,Generator loss:4.213236\n",
            "\n",
            "Epoch 102/400, Time: 25.629483222961426, Discriminator loss:0.8602035,Generator loss:5.2431684\n",
            "\n",
            "Epoch 103/400, Time: 25.499189138412476, Discriminator loss:0.83360213,Generator loss:3.9591439\n",
            "\n",
            "Epoch 104/400, Time: 25.523216724395752, Discriminator loss:0.73354226,Generator loss:4.4843025\n",
            "\n",
            "Epoch 105/400, Time: 25.584721088409424, Discriminator loss:0.7372353,Generator loss:3.8854778\n",
            "\n",
            "Epoch 106/400, Time: 25.586840629577637, Discriminator loss:0.72148097,Generator loss:4.175126\n",
            "\n",
            "Epoch 107/400, Time: 25.548657178878784, Discriminator loss:0.81335497,Generator loss:4.5314364\n",
            "\n",
            "Epoch 108/400, Time: 25.55713176727295, Discriminator loss:0.7668158,Generator loss:3.5022354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jKzEr9e0BVbo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Display final image\n",
        "!pip install numpy\n",
        "import cv2\n",
        "image = cv2.imread('./figures/current_batch.png')\n",
        "cv2.imshow('Celeb Faces',image)\n",
        "\n",
        "#%pylab inline\n",
        "#import matplotlib.pyplot as plt\n",
        "#import matplotlib.image as mpimg\n",
        "#img=mpimg.imread('your_image.png')\n",
        "#imgplot = plt.imshow(img)\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMArMNyOUfz0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#import os, signal\n",
        "#os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}