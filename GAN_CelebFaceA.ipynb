{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3cLJSP8tdJf7"
   },
   "outputs": [],
   "source": [
    "#!kill -9 -1\n",
    "#import os, signal\n",
    "#os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9851,
     "status": "ok",
     "timestamp": 1528737097314,
     "user": {
      "displayName": "Siddhartha Lodha",
      "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
      "userId": "117940677094137339921"
     },
     "user_tz": -330
    },
    "id": "K70hAckqg0EA",
    "outputId": "24e2f9f9-e7d9-4e39-dd77-a100035b5a7b"
   },
   "outputs": [],
   "source": [
    "# https://keras.io/\n",
    "!pip install -q keras\n",
    "import keras\n",
    "#!apt --fix-broken install\n",
    "#In a new virtual environment\n",
    "#!pip install scipy==0.18.1\n",
    "!pip install plotnine\n",
    "from plotnine import ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TsO9WacsQbMC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Deconv2D, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import Input, Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.utils import generic_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.generic_utils import Progbar\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "#!git clone https://github.com/siddharthalodha/mlsid.git\n",
    "    \n",
    "#!cp -r mlsid/models .\n",
    "#!cp -r mlsid/figures .\n",
    "#!cp -r mlsid/utils .\n",
    "\n",
    "sys.path.append(\"./utils\") # Utils\n",
    "import general_utils\n",
    "import data_utils\n",
    "\n",
    "#!mkdir /figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ExF9V5Qwdai-"
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "backend=\"tensorflow\" #Specify backend to be used\n",
    "dset=\"celebA\" #Specify dataset to be used, currently supported : mnist/celebA\n",
    "generator=\"upsampling\" #Generator to be used : upsampling/deconv\n",
    "model_name=\"CNN\" #Name of model\n",
    "batch_size=32 #Batch size to be used \n",
    "n_batch_per_epoch=200 #Number of batches per epoch\n",
    "nb_epoch=400 #Number of epochs\n",
    "epoch=10 #Epoch size => Used for progress bars \n",
    "nb_classes=2 #Number of classes\n",
    "do_plot=True #Plotting during execution\n",
    "bn_mode=2 #Batch normalization\n",
    "img_dim=64 #Dimension of image\n",
    "label_smoothing=\"store_true\" #Label smoothing\n",
    "label_flipping=0 #Label flipping\n",
    "noise_scale=0.5 \n",
    "use_mbd=\"store_true\"\n",
    "image_data_format = \"channels_last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2012,
     "status": "ok",
     "timestamp": 1528737401530,
     "user": {
      "displayName": "Siddhartha Lodha",
      "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
      "userId": "117940677094137339921"
     },
     "user_tz": -330
    },
    "id": "hH5ebnAGSCyE",
    "outputId": "4dda45f2-95a0-480b-ce61-7f59cae406d9"
   },
   "outputs": [],
   "source": [
    "#Code to download CelebA hdf5 dataset from google drive\n",
    "#!pip install PyDrive\n",
    "\n",
    "#from google.colab import auth\n",
    "#from oauth2client.client import GoogleCredentials\n",
    "#from pydrive.auth import GoogleAuth\n",
    "#from pydrive.drive import GoogleDrive\n",
    "\n",
    "#auth.authenticate_user()\n",
    "#gauth = GoogleAuth()\n",
    "#gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#drive = GoogleDrive(gauth)\n",
    "\n",
    "#fileId = drive.CreateFile({'id': '1cUBPxqU-9Y6f_OAfPwdRmPg7ruZ2sfdk'})\n",
    "#print(fileId['title'])  # CelebA Dataset\n",
    "#fileId.GetContentFile('CelebA_64_data.h5')  # Save Drive file as a local file\n",
    "\n",
    "#fileId = drive.CreateFile({'id': '10B5fIjTwgk1IyXNGbWTzYEXMxnbFixTJ'})\n",
    "#print(fileId['title'])  # CelebA Dataset\n",
    "#fileId.GetContentFile('MNIST.h5')  # Save Drive file as a local file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1535,
     "status": "ok",
     "timestamp": 1528737403105,
     "user": {
      "displayName": "Siddhartha Lodha",
      "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
      "userId": "117940677094137339921"
     },
     "user_tz": -330
    },
    "id": "ElbiB72ccM4Y",
    "outputId": "fba966cf-fee4-4544-d239-658b0f7ce0d1"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "      raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "luzh9Wm2ccMp"
   },
   "outputs": [],
   "source": [
    "def generator_upsampling(noise_dim, img_dim, bn_mode, model_name=\"generator_upsampling\", dset=\"celebA\"):\n",
    "    \"\"\"\n",
    "    Generator model of the DCGAN\n",
    "    args : img_dim (tuple of int) num_chan, height, width\n",
    "           pretr_weights_file (str) file holding pre trained weights\n",
    "    returns : model (keras NN) the Neural Net model\n",
    "    \"\"\"\n",
    "\n",
    "    s = img_dim[1]\n",
    "    f = 512\n",
    "\n",
    "    if dset == \"mnist\":\n",
    "        start_dim = int(s / 4)\n",
    "        nb_upconv = 2\n",
    "    else:\n",
    "        start_dim = int(s / 16)\n",
    "        nb_upconv = 4\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        bn_axis = 1\n",
    "        reshape_shape = (f, start_dim, start_dim)\n",
    "        output_channels = img_dim[0]\n",
    "    else:\n",
    "        reshape_shape = (start_dim, start_dim, f)\n",
    "        bn_axis = -1\n",
    "        output_channels = img_dim[-1]\n",
    "\n",
    "    gen_input = Input(shape=noise_dim, name=\"generator_input\")\n",
    "\n",
    "    x = Dense(f * start_dim * start_dim, input_dim=noise_dim)(gen_input)\n",
    "    x = Reshape(reshape_shape)(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Upscaling blocks\n",
    "    for i in range(nb_upconv):\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        nb_filters = int(f / (2 ** (i + 1)))\n",
    "        x = Conv2D(nb_filters, (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization(axis=1)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(nb_filters, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(output_channels, (3, 3), name=\"gen_Conv2D_final\", padding=\"same\", activation='tanh')(x)\n",
    "\n",
    "    generator_model = Model(inputs=[gen_input], outputs=[x], name=model_name)\n",
    "\n",
    "    return generator_model\n",
    "\n",
    "\n",
    "def generator_deconv(noise_dim, img_dim, bn_mode, batch_size, model_name=\"generator_deconv\", dset=\"mnist\"):\n",
    "    \"\"\"\n",
    "    Generator model of the DCGAN\n",
    "    args : nb_classes (int) number of classes\n",
    "           img_dim (tuple of int) num_chan, height, width\n",
    "           pretr_weights_file (str) file holding pre trained weights\n",
    "    returns : model (keras NN) the Neural Net model\n",
    "    \"\"\"\n",
    "\n",
    "    assert K.backend() == \"tensorflow\", \"Deconv not implemented with theano\"\n",
    "\n",
    "    s = img_dim[1]\n",
    "    f = 512\n",
    "\n",
    "    if dset == \"mnist\":\n",
    "        start_dim = int(s / 4)\n",
    "        nb_upconv = 2\n",
    "    else:\n",
    "        start_dim = int(s / 16)\n",
    "        nb_upconv = 4\n",
    "\n",
    "    reshape_shape = (start_dim, start_dim, f)\n",
    "    bn_axis = -1\n",
    "    output_channels = img_dim[-1]\n",
    "\n",
    "    gen_input = Input(shape=noise_dim, name=\"generator_input\")\n",
    "\n",
    "    x = Dense(f * start_dim * start_dim, input_dim=noise_dim)(gen_input)\n",
    "    x = Reshape(reshape_shape)(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Transposed conv blocks\n",
    "    for i in range(nb_upconv - 1):\n",
    "        nb_filters = int(f / (2 ** (i + 1)))\n",
    "        s = start_dim * (2 ** (i + 1))\n",
    "        o_shape = (batch_size, s, s, nb_filters)\n",
    "        x = Deconv2D(nb_filters, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Last block\n",
    "    s = start_dim * (2 ** (nb_upconv))\n",
    "    o_shape = (batch_size, s, s, output_channels)\n",
    "    x = Deconv2D(output_channels, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
    "    x = Activation(\"tanh\")(x)\n",
    "\n",
    "    generator_model = Model(inputs=[gen_input], outputs=[x], name=model_name)\n",
    "\n",
    "    return generator_model\n",
    "\n",
    "\n",
    "def DCGAN_discriminator(noise_dim, img_dim, bn_mode, model_name=\"DCGAN_discriminator\", dset=\"celebA\", use_mbd=False):\n",
    "    \"\"\"\n",
    "    Discriminator model of the DCGAN\n",
    "    args : img_dim (tuple of int) num_chan, height, width\n",
    "           pretr_weights_file (str) file holding pre trained weights\n",
    "    returns : model (keras NN) the Neural Net model\n",
    "    \"\"\"\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = -1\n",
    "\n",
    "    disc_input = Input(shape=img_dim, name=\"discriminator_input\")\n",
    "\n",
    "    if dset == \"mnist\":\n",
    "        list_f = [128]\n",
    "\n",
    "    else:\n",
    "        list_f = [64, 128, 256]\n",
    "\n",
    "    # First conv\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), name=\"disc_Conv2D_1\", padding=\"same\")(disc_input)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    # Next convs\n",
    "    for i, f in enumerate(list_f):\n",
    "        name = \"disc_Conv2D_%s\" % (i + 2)\n",
    "        x = Conv2D(f, (3, 3), strides=(2, 2), name=name, padding=\"same\")(x)\n",
    "        x = BatchNormalization(axis=bn_axis)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    def minb_disc(x):\n",
    "        diffs = K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, [1, 2, 0]), 0)\n",
    "        abs_diffs = K.sum(K.abs(diffs), 2)\n",
    "        x = K.sum(K.exp(-abs_diffs), 2)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def lambda_output(input_shape):\n",
    "        return input_shape[:2]\n",
    "\n",
    "    num_kernels = 100\n",
    "    dim_per_kernel = 5\n",
    "\n",
    "    M = Dense(num_kernels * dim_per_kernel, use_bias=False, activation=None)\n",
    "    MBD = Lambda(minb_disc, output_shape=lambda_output)\n",
    "\n",
    "    if use_mbd:\n",
    "        x_mbd = M(x)\n",
    "        x_mbd = Reshape((num_kernels, dim_per_kernel))(x_mbd)\n",
    "        x_mbd = MBD(x_mbd)\n",
    "        x = Concatenate(axis=bn_axis)([x, x_mbd])\n",
    "\n",
    "    x = Dense(2, activation='softmax', name=\"disc_dense_2\")(x)\n",
    "\n",
    "    discriminator_model = Model(inputs=[disc_input], outputs=[x], name=model_name)\n",
    "\n",
    "    return discriminator_model\n",
    "\n",
    "\n",
    "def DCGAN(generator, discriminator_model, noise_dim, img_dim):\n",
    "\n",
    "    noise_input = Input(shape=noise_dim, name=\"noise_input\")\n",
    "\n",
    "    generated_image = generator(noise_input)\n",
    "    DCGAN_output = discriminator_model(generated_image)\n",
    "\n",
    "    DCGAN = Model(inputs=[noise_input],\n",
    "                  outputs=[DCGAN_output],\n",
    "                  name=\"DCGAN\")\n",
    "    return DCGAN\n",
    "\n",
    "\n",
    "def load(model_name, noise_dim, img_dim, bn_mode, batch_size, dset=\"mnist\", use_mbd=False):\n",
    "\n",
    "    if model_name == \"generator_upsampling\":\n",
    "        model = generator_upsampling(noise_dim, img_dim, bn_mode, model_name=model_name, dset=dset)\n",
    "        model.summary()\n",
    "        #plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
    "        return model\n",
    "    if model_name == \"generator_deconv\":\n",
    "        model = generator_deconv(noise_dim, img_dim, bn_mode, batch_size, model_name=model_name, dset=dset)\n",
    "        model.summary()\n",
    "        #plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
    "        return model\n",
    "    if model_name == \"DCGAN_discriminator\":\n",
    "        model = DCGAN_discriminator(noise_dim, img_dim, bn_mode, model_name=model_name, dset=dset, use_mbd=use_mbd)\n",
    "        model.summary()\n",
    "        #plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JYvIBjcLcg_F"
   },
   "outputs": [],
   "source": [
    "def train_GAN(batch_size,n_batch_per_epoch,nb_epoch,generator,model_name,image_data_format,img_dim,bn_mode,label_smoothing,label_flipping,noise_scale,dset,use_mbd,epoch_size):\n",
    "    # Setup environment (logging directory etc)\n",
    "    #general_utils.setup_logging(model_name) #change this if setup_logging moved to separate file\n",
    "\n",
    "    # Load and rescale data\n",
    "    if dset == \"celebA\":\n",
    "        X_real_train = data_utils.load_celebA(img_dim, image_data_format) #change func call if file moved\n",
    "    if dset == \"mnist\":\n",
    "        X_real_train, _, _, _ = data_utils.load_mnist(image_data_format) #change func call if file moved\n",
    "    img_dim = X_real_train.shape[-3:]\n",
    "    noise_dim = (100,)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        # Create optimizers\n",
    "        opt_dcgan = Adam(lr=1E-3, beta_1=0.5, beta_2=0.999, epsilon=1e-08)\n",
    "        opt_discriminator = SGD(lr=1E-3, momentum=0.9, nesterov=True)\n",
    "\n",
    "        # Load generator model\n",
    "        generator_model = load(\"generator_%s\" % generator,\n",
    "                                      noise_dim,\n",
    "                                      img_dim,\n",
    "                                      bn_mode,\n",
    "                                      batch_size,\n",
    "                                      dset=dset,\n",
    "                                      use_mbd=use_mbd)\n",
    "        \n",
    "        # Load discriminator model\n",
    "        discriminator_model = load(\"DCGAN_discriminator\",\n",
    "                                          noise_dim,\n",
    "                                          img_dim,\n",
    "                                          bn_mode,\n",
    "                                          batch_size,\n",
    "                                          dset=dset,\n",
    "                                          use_mbd=use_mbd)\n",
    "\n",
    "        generator_model.compile(loss='mse', optimizer=opt_discriminator)\n",
    "        discriminator_model.trainable = False\n",
    "        DCGAN_model = DCGAN(generator_model,\n",
    "                                   discriminator_model,\n",
    "                                   noise_dim,\n",
    "                                   img_dim)\n",
    "        \n",
    "        loss = ['binary_crossentropy']\n",
    "        loss_weights = [1]\n",
    "        DCGAN_model.compile(loss=loss, loss_weights=loss_weights, optimizer=opt_dcgan)\n",
    "\n",
    "        discriminator_model.trainable = True\n",
    "        discriminator_model.compile(loss='binary_crossentropy', optimizer=opt_discriminator)\n",
    "\n",
    "        gen_loss = 100\n",
    "        disc_loss = 100\n",
    "\n",
    "        # Start training\n",
    "        print(\"Start training\")\n",
    "        for e in range(nb_epoch):\n",
    "            # Initialize progbar and batch counter\n",
    "            #progbar = Progbar(epoch_size)\n",
    "            batch_counter = 1\n",
    "            start = time.time()\n",
    "            for X_real_batch in data_utils.gen_batch(X_real_train, batch_size):\n",
    "\n",
    "                # Create a batch to feed the discriminator model\n",
    "                X_disc, y_disc = data_utils.get_disc_batch(X_real_batch,\n",
    "                                                           generator_model,\n",
    "                                                           batch_counter,\n",
    "                                                           batch_size,\n",
    "                                                           noise_dim,\n",
    "                                                           noise_scale=noise_scale,\n",
    "                                                           label_smoothing=label_smoothing,\n",
    "                                                           label_flipping=label_flipping)\n",
    "\n",
    "                # Update the discriminator\n",
    "                disc_loss = discriminator_model.train_on_batch(X_disc, y_disc)\n",
    "\n",
    "                # Create a batch to feed the generator model\n",
    "                X_gen, y_gen = data_utils.get_gen_batch(batch_size, noise_dim, noise_scale=noise_scale)\n",
    "\n",
    "                # Freeze the discriminator\n",
    "                discriminator_model.trainable = False\n",
    "                gen_loss = DCGAN_model.train_on_batch(X_gen, y_gen)\n",
    "                # Unfreeze the discriminator\n",
    "                discriminator_model.trainable = True\n",
    "\n",
    "                batch_counter += 1\n",
    "                #progbar.add(batch_size, values=[(\"D logloss\", disc_loss),\n",
    "                #                                (\"G logloss\", gen_loss)])\n",
    "\n",
    "                 #Save images for visualization\n",
    "                if batch_counter % 100 == 0:\n",
    "                     data_utils.plot_generated_batch(X_real_batch, generator_model,\n",
    "                                                    batch_size, noise_dim, image_data_format)\n",
    "                    \n",
    "                if batch_counter >= n_batch_per_epoch:\n",
    "                    break\n",
    "\n",
    "            print(\"\")\n",
    "            print('Epoch %s/%s, Time: %s, Discriminator loss:%s,Generator loss:%s' % (e + 1, nb_epoch, time.time() - start,disc_loss,gen_loss))\n",
    "\n",
    "            if e % 5 == 0:\n",
    "                gen_weights_path = os.path.join('./models/%s/gen_weights_epoch%s.h5' % (model_name, e))\n",
    "                generator_model.save_weights(gen_weights_path, overwrite=True)\n",
    "\n",
    "                disc_weights_path = os.path.join('./models/%s/disc_weights_epoch%s.h5' % (model_name, e))\n",
    "                discriminator_model.save_weights(disc_weights_path, overwrite=True)\n",
    "\n",
    "                DCGAN_weights_path = os.path.join('./models/%s/DCGAN_weights_epoch%s.h5' % (model_name, e))\n",
    "                DCGAN_model.save_weights(DCGAN_weights_path, overwrite=True)\n",
    "    except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1411
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3324,
     "status": "ok",
     "timestamp": 1528737417982,
     "user": {
      "displayName": "Siddhartha Lodha",
      "photoUrl": "//lh4.googleusercontent.com/-ywMMTs1Ky78/AAAAAAAAAAI/AAAAAAAAABw/HVTRDDvhVZY/s50-c-k-no/photo.jpg",
      "userId": "117940677094137339921"
     },
     "user_tz": -330
    },
    "id": "VNolsYjGcsAH",
    "outputId": "ecb51724-1512-459d-fedf-52c5af7e0c69",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "image_data_format = \"channels_last\"\n",
    "K.set_image_data_format(image_data_format)    \n",
    "# Launch training\n",
    "train_GAN(batch_size,n_batch_per_epoch,nb_epoch,generator,model_name,image_data_format,img_dim,bn_mode,label_smoothing,label_flipping,noise_scale,dset,use_mbd,epoch) #change func if file is moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jMArMNyOUfz0"
   },
   "outputs": [],
   "source": [
    "#import os, signal\n",
    "#os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "GAN_CelebFaceA.ipynb",
   "provenance": [
    {
     "file_id": "1OeNzGPshHmF_jwN1lv5BYX0HJNTV5AjE",
     "timestamp": 1528645865817
    },
    {
     "file_id": "https://github.com/siddharthalodha/mlsid/blob/master/GAN_CelebFaceA.ipynb",
     "timestamp": 1528627132682
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
