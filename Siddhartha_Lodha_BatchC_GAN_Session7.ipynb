{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siddhartha_Lodha_BatchC_GAN_Session7.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1OeNzGPshHmF_jwN1lv5BYX0HJNTV5AjE",
          "timestamp": 1528645865817
        },
        {
          "file_id": "https://github.com/siddharthalodha/mlsid/blob/master/GAN_CelebFaceA.ipynb",
          "timestamp": 1528627132682
        }
      ],
      "collapsed_sections": [
        "XfVV57Kjm0Ws",
        "QMZiFlXToXZt",
        "8S8a8XafoSC5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3cLJSP8tdJf7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Source : https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/GAN \n",
        "# Project Title : Convert GAN implementation into IPython Notebook\n",
        "\n",
        "# Current Progress\n",
        "# 1. Convert main model,training files\n",
        "# 2. Create HDF5 dataset to be used for training\n",
        "# 3. Trained network on CelebA dataset for 400 epochs\n",
        "# 4. Improve implementation to generate better quality images using other GAN implementations like BEGAN, PGGAN etc. (WIP)\n",
        "# 5. Add descriptions in code (WIP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvRwO4lXb43a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/siddharthalodha/DCGAN_KERAS.git\n",
        "!cp -r DCGAN_KERAS/models .\n",
        "!cp -r DCGAN_KERAS/figures .\n",
        "!cp -r DCGAN_KERAS/utils .  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cYZnHjDWo_5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download CelebA dataset from Google drive"
      ]
    },
    {
      "metadata": {
        "id": "hH5ebnAGSCyE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Code to download CelebA hdf5 dataset from google drive\n",
        "!pip install PyDrive\n",
        "\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileId = drive.CreateFile({'id': '1cUBPxqU-9Y6f_OAfPwdRmPg7ruZ2sfdk'})\n",
        "print(fileId['title'])  # CelebA Dataset\n",
        "fileId.GetContentFile('CelebA_64_data.h5')  # Save Drive file as a local file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PaXNaYA0pFJy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ]
    },
    {
      "metadata": {
        "id": "PHzXF_Pua7-o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "#Fixing graphviz pydot installation for plot_model function to work\n",
        "#!sudo apt-get install graphviz\n",
        "#!pip install pydot\n",
        "#!pip install graphviz\n",
        "#!pip install graphviz pydot\n",
        "\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "\n",
        "import graphviz\n",
        "import pydot\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matplotlib.style.use('ggplot')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TsO9WacsQbMC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Deconv2D, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers import Input, Concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from keras.utils import generic_utils\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.generic_utils import Progbar\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "sys.path.append(\"./utils\") # Utils\n",
        "import general_utils\n",
        "import data_utils #Being used for importing data,generating batches (CelebA Data is currently stored in an hdf5 file)\n",
        "%matplotlib inline\n",
        "\n",
        "#!mkdir /figures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1IAdQDqvqbcy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Check the Version of TensorFlow and Access to GPU **"
      ]
    },
    {
      "metadata": {
        "id": "ElbiB72ccM4Y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "      raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "K.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTF0BdULpJ-I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "ExF9V5Qwdai-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "\n",
        "backend=\"tensorflow\" #Specify backend to be used\n",
        "dset=\"celebA\" #Specify dataset to be used, currently supported : mnist/celebA\n",
        "generator=\"upsampling\" #Generator to be used : upsampling/deconv\n",
        "model_name=\"CNN\" #Name of model\n",
        "batch_size=32 #Batch size to be used \n",
        "n_batch_per_epoch=200 #Number of batches per epoch\n",
        "nb_epoch=400 #Number of epochs\n",
        "epoch=10 #Epoch size => Used for progress bars \n",
        "nb_classes=2 #Number of classes\n",
        "do_plot=True #Plotting during execution\n",
        "bn_mode=2 #Batch normalization\n",
        "img_dim=64 #Dimension of image\n",
        "label_smoothing=\"store_true\" #Label smoothing\n",
        "label_flipping=0 #Label flipping\n",
        "noise_scale=0.5 \n",
        "use_mbd=\"store_true\"\n",
        "image_data_format = \"channels_last\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XfVV57Kjm0Ws",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Define generator function#1 : Upsampling\n",
        "\n",
        "Preferable for CelebA dataset"
      ]
    },
    {
      "metadata": {
        "id": "luzh9Wm2ccMp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def generator_upsampling(noise_dim, img_dim, bn_mode, model_name=\"generator_upsampling\", dset=\"celebA\"):\n",
        "    \"\"\"\n",
        "    Generator model of the DCGAN\n",
        "    args : img_dim (tuple of int) num_chan, height, width\n",
        "           pretr_weights_file (str) file holding pre trained weights\n",
        "    returns : model (keras NN) the Neural Net model\n",
        "    \"\"\"\n",
        "\n",
        "    s = img_dim[1]\n",
        "    f = 512\n",
        "\n",
        "    if dset == \"mnist\":\n",
        "        start_dim = int(s / 4)\n",
        "        nb_upconv = 2\n",
        "    else:\n",
        "        start_dim = int(s / 16)\n",
        "        nb_upconv = 4\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        bn_axis = 1\n",
        "        reshape_shape = (f, start_dim, start_dim)\n",
        "        output_channels = img_dim[0]\n",
        "    else:\n",
        "        reshape_shape = (start_dim, start_dim, f)\n",
        "        bn_axis = -1\n",
        "        output_channels = img_dim[-1]\n",
        "\n",
        "    gen_input = Input(shape=noise_dim, name=\"generator_input\")\n",
        "\n",
        "    x = Dense(f * start_dim * start_dim, input_dim=noise_dim)(gen_input)\n",
        "    x = Reshape(reshape_shape)(x)\n",
        "    x = BatchNormalization(axis=bn_axis)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Upscaling blocks\n",
        "    for i in range(nb_upconv):\n",
        "        x = UpSampling2D(size=(2, 2))(x)\n",
        "        nb_filters = int(f / (2 ** (i + 1)))\n",
        "        x = Conv2D(nb_filters, (3, 3), padding=\"same\")(x)\n",
        "        x = BatchNormalization(axis=1)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2D(nb_filters, (3, 3), padding=\"same\")(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(output_channels, (3, 3), name=\"gen_Conv2D_final\", padding=\"same\", activation='tanh')(x)\n",
        "\n",
        "    generator_model = Model(inputs=[gen_input], outputs=[x], name=model_name)\n",
        "\n",
        "    return generator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMZiFlXToXZt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define generator function#2 : Deconvolution\n",
        "\n",
        "Preferable for MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "L7E3w4MFa7_I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def generator_deconv(noise_dim, img_dim, bn_mode, batch_size, model_name=\"generator_deconv\", dset=\"mnist\"):\n",
        "    \"\"\"\n",
        "    Generator model of the DCGAN\n",
        "    args : nb_classes (int) number of classes\n",
        "           img_dim (tuple of int) num_chan, height, width\n",
        "           pretr_weights_file (str) file holding pre trained weights\n",
        "    returns : model (keras NN) the Neural Net model\n",
        "    \"\"\"\n",
        "\n",
        "    assert K.backend() == \"tensorflow\", \"Deconv not implemented with theano\"\n",
        "\n",
        "    s = img_dim[1]\n",
        "    f = 512\n",
        "\n",
        "    if dset == \"mnist\":\n",
        "        start_dim = int(s / 4)\n",
        "        nb_upconv = 2\n",
        "    else:\n",
        "        start_dim = int(s / 16)\n",
        "        nb_upconv = 4\n",
        "\n",
        "    reshape_shape = (start_dim, start_dim, f)\n",
        "    bn_axis = -1\n",
        "    output_channels = img_dim[-1]\n",
        "\n",
        "    gen_input = Input(shape=noise_dim, name=\"generator_input\")\n",
        "\n",
        "    x = Dense(f * start_dim * start_dim, input_dim=noise_dim)(gen_input)\n",
        "    x = Reshape(reshape_shape)(x)\n",
        "    x = BatchNormalization(axis=bn_axis)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Transposed conv blocks\n",
        "    for i in range(nb_upconv - 1):\n",
        "        nb_filters = int(f / (2 ** (i + 1)))\n",
        "        s = start_dim * (2 ** (i + 1))\n",
        "        o_shape = (batch_size, s, s, nb_filters)\n",
        "        x = Deconv2D(nb_filters, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
        "        x = BatchNormalization(axis=-1)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Last block\n",
        "    s = start_dim * (2 ** (nb_upconv))\n",
        "    o_shape = (batch_size, s, s, output_channels)\n",
        "    x = Deconv2D(output_channels, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
        "    x = Activation(\"tanh\")(x)\n",
        "\n",
        "    generator_model = Model(inputs=[gen_input], outputs=[x], name=model_name)\n",
        "\n",
        "    return generator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2570kiMDlzdx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define discriminator function\n",
        "\n",
        "Implement discriminator to create a discriminator neural network that discriminates on images. \n"
      ]
    },
    {
      "metadata": {
        "id": "_tA4upbqa7_Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def DCGAN(generator, discriminator_model, noise_dim, img_dim):\n",
        "\n",
        "    noise_input = Input(shape=noise_dim, name=\"noise_input\")\n",
        "\n",
        "    generated_image = generator(noise_input)\n",
        "    DCGAN_output = discriminator_model(generated_image)\n",
        "\n",
        "    DCGAN = Model(inputs=[noise_input],\n",
        "                  outputs=[DCGAN_output],\n",
        "                  name=\"DCGAN\")\n",
        "    return DCGAN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVGxtwbHa7_b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def DCGAN_discriminator(noise_dim, img_dim, bn_mode, model_name=\"DCGAN_discriminator\", dset=\"celebA\", use_mbd=False):\n",
        "    \"\"\"\n",
        "    Discriminator model of the DCGAN\n",
        "    args : img_dim (tuple of int) num_chan, height, width\n",
        "           pretr_weights_file (str) file holding pre trained weights\n",
        "    returns : model (keras NN) the Neural Net model\n",
        "    \"\"\"\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        bn_axis = 1\n",
        "    else:\n",
        "        bn_axis = -1\n",
        "\n",
        "    disc_input = Input(shape=img_dim, name=\"discriminator_input\")\n",
        "\n",
        "    if dset == \"mnist\":\n",
        "        list_f = [128]\n",
        "\n",
        "    else:\n",
        "        list_f = [64, 128, 256]\n",
        "\n",
        "    # First conv\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), name=\"disc_Conv2D_1\", padding=\"same\")(disc_input)\n",
        "    x = BatchNormalization(axis=bn_axis)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    # Next convs\n",
        "    for i, f in enumerate(list_f):\n",
        "        name = \"disc_Conv2D_%s\" % (i + 2)\n",
        "        x = Conv2D(f, (3, 3), strides=(2, 2), name=name, padding=\"same\")(x)\n",
        "        x = BatchNormalization(axis=bn_axis)(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    def minb_disc(x):\n",
        "        diffs = K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, [1, 2, 0]), 0)\n",
        "        abs_diffs = K.sum(K.abs(diffs), 2)\n",
        "        x = K.sum(K.exp(-abs_diffs), 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def lambda_output(input_shape):\n",
        "        return input_shape[:2]\n",
        "\n",
        "    num_kernels = 100\n",
        "    dim_per_kernel = 5\n",
        "\n",
        "    M = Dense(num_kernels * dim_per_kernel, use_bias=False, activation=None)\n",
        "    MBD = Lambda(minb_disc, output_shape=lambda_output)\n",
        "\n",
        "    if use_mbd:\n",
        "        x_mbd = M(x)\n",
        "        x_mbd = Reshape((num_kernels, dim_per_kernel))(x_mbd)\n",
        "        x_mbd = MBD(x_mbd)\n",
        "        x = Concatenate(axis=bn_axis)([x, x_mbd])\n",
        "\n",
        "    x = Dense(2, activation='softmax', name=\"disc_dense_2\")(x)\n",
        "\n",
        "    discriminator_model = Model(inputs=[disc_input], outputs=[x], name=model_name)\n",
        "\n",
        "    return discriminator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8S8a8XafoSC5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define model loader\n",
        "\n",
        "Implement loader to load specific models : \n",
        "1. Generators : Upsampling, Deconvolution\n",
        "2. Discriminator : DCGAN\n"
      ]
    },
    {
      "metadata": {
        "id": "QqZdwU2ta7_W",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def load(model_name, noise_dim, img_dim, bn_mode, batch_size, dset=\"mnist\", use_mbd=False):\n",
        "\n",
        "    if model_name == \"generator_upsampling\":\n",
        "        model = generator_upsampling(noise_dim, img_dim, bn_mode, model_name=model_name, dset=dset)\n",
        "        model.summary()\n",
        "        plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
        "        return model\n",
        "    if model_name == \"generator_deconv\":\n",
        "        model = generator_deconv(noise_dim, img_dim, bn_mode, batch_size, model_name=model_name, dset=dset)\n",
        "        model.summary()\n",
        "        plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
        "        return model\n",
        "    if model_name == \"DCGAN_discriminator\":\n",
        "        model = DCGAN_discriminator(noise_dim, img_dim, bn_mode, model_name=model_name, dset=dset, use_mbd=use_mbd)\n",
        "        model.summary()\n",
        "        plot_model(model, to_file='./figures/%s.png' % model_name, show_shapes=True, show_layer_names=True)\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sTTyuNwzn-Nl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the network\n",
        "\n",
        "> **Optimizer used** : \n",
        "\n",
        ">> DCGAN : Adam with LR .0002\n",
        "\n",
        ">> Discriminator : SGD with momentum and LR 0.001\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JYvIBjcLcg_F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train_GAN(batch_size,n_batch_per_epoch,nb_epoch,generator,model_name,image_data_format,img_dim,bn_mode,label_smoothing,label_flipping,noise_scale,dset,use_mbd,epoch_size):\n",
        "    # Setup environment (logging directory etc)\n",
        "    general_utils.setup_logging(model_name)\n",
        "\n",
        "    # Load and rescale data\n",
        "    if dset == \"celebA\":\n",
        "        X_real_train = data_utils.load_celebA(img_dim, image_data_format)\n",
        "    if dset == \"mnist\":\n",
        "        X_real_train, _, _, _ = data_utils.load_mnist(image_data_format)\n",
        "    img_dim = X_real_train.shape[-3:]\n",
        "    noise_dim = (100,)\n",
        "    \n",
        "    try:\n",
        "\n",
        "        # Create optimizers\n",
        "        opt_dcgan = Adam(lr=2E-4, beta_1=0.5, beta_2=0.999, epsilon=1e-08)\n",
        "        opt_discriminator = SGD(lr=1E-3, momentum=0.9, nesterov=True)\n",
        "\n",
        "        # Load generator model\n",
        "        generator_model = load(\"generator_%s\" % generator,\n",
        "                                      noise_dim,\n",
        "                                      img_dim,\n",
        "                                      bn_mode,\n",
        "                                      batch_size,\n",
        "                                      dset=dset,\n",
        "                                      use_mbd=use_mbd)\n",
        "        \n",
        "        # Load discriminator model\n",
        "        discriminator_model = load(\"DCGAN_discriminator\",\n",
        "                                          noise_dim,\n",
        "                                          img_dim,\n",
        "                                          bn_mode,\n",
        "                                          batch_size,\n",
        "                                          dset=dset,\n",
        "                                          use_mbd=use_mbd)\n",
        "\n",
        "        generator_model.compile(loss='mse', optimizer=opt_discriminator)\n",
        "        discriminator_model.trainable = False\n",
        "        DCGAN_model = DCGAN(generator_model,\n",
        "                                   discriminator_model,\n",
        "                                   noise_dim,\n",
        "                                   img_dim)\n",
        "        \n",
        "        loss = ['binary_crossentropy']\n",
        "        loss_weights = [1]\n",
        "        DCGAN_model.compile(loss=loss, loss_weights=loss_weights, optimizer=opt_dcgan) #Compile DCGAN model with optimizer as adam\n",
        "\n",
        "        discriminator_model.trainable = True\n",
        "        discriminator_model.compile(loss='binary_crossentropy', optimizer=opt_discriminator)\n",
        "\n",
        "        #Initiliaze generator and discriminator loss\n",
        "        gen_loss = 100\n",
        "        disc_loss = 100\n",
        "\n",
        "        # Start training for epochs=nb_epoch \n",
        "        print(\"Start training\")\n",
        "        for e in range(nb_epoch):\n",
        "            #Initialize progbar and batch counter\n",
        "            progbar = Progbar(epoch_size) #Check Progbar logic also before, tensorboard implementation\n",
        "            batch_counter = 1\n",
        "            start = time.time()\n",
        "            for X_real_batch in data_utils.gen_batch(X_real_train, batch_size):\n",
        "\n",
        "                # Create a batch to feed the discriminator model\n",
        "                X_disc, y_disc = data_utils.get_disc_batch(X_real_batch,\n",
        "                                                           generator_model,\n",
        "                                                           batch_counter,\n",
        "                                                           batch_size,\n",
        "                                                           noise_dim,\n",
        "                                                           noise_scale=noise_scale,\n",
        "                                                           label_smoothing=label_smoothing,\n",
        "                                                           label_flipping=label_flipping)\n",
        "\n",
        "                # Update the discriminator\n",
        "                #train_on_batch is used for training instead of the traditional model.fit because we need to update existing trained model on new batch.\n",
        "                disc_loss = discriminator_model.train_on_batch(X_disc, y_disc)\n",
        "\n",
        "                # Create a batch to feed the generator model\n",
        "                X_gen, y_gen = data_utils.get_gen_batch(batch_size, noise_dim, noise_scale=noise_scale)\n",
        "\n",
        "                # Freeze the discriminator\n",
        "                discriminator_model.trainable = False\n",
        "                gen_loss = DCGAN_model.train_on_batch(X_gen, y_gen)\n",
        "                # Unfreeze the discriminator\n",
        "                discriminator_model.trainable = True\n",
        "\n",
        "                batch_counter += 1\n",
        "                progbar.add(batch_size, values=[(\"D logloss\", disc_loss),\n",
        "                                                (\"G logloss\", gen_loss)])\n",
        "\n",
        "                 #Save images for visualization\n",
        "                if batch_counter % 100 == 0:\n",
        "                    data_utils.plot_generated_batch(X_real_batch, generator_model,\n",
        "                                                    batch_size, noise_dim, image_data_format)\n",
        "                    \n",
        "                if batch_counter >= n_batch_per_epoch:\n",
        "                    break\n",
        "\n",
        "            print(\"\")\n",
        "            print('Epoch %s/%s, Time: %s, Discriminator loss:%s,Generator loss:%s' % (e + 1, nb_epoch, time.time() - start,disc_loss,gen_loss))\n",
        "\n",
        "            #Save weights for generator,discriminator and DCGAN\n",
        "            if e % 5 == 0:\n",
        "                gen_weights_path = os.path.join('./models/%s/gen_weights_epoch%s.h5' % (model_name, e))\n",
        "                generator_model.save_weights(gen_weights_path, overwrite=True)\n",
        "\n",
        "                disc_weights_path = os.path.join('./models/%s/disc_weights_epoch%s.h5' % (model_name, e))\n",
        "                discriminator_model.save_weights(disc_weights_path, overwrite=True)\n",
        "\n",
        "                DCGAN_weights_path = os.path.join('./models/%s/DCGAN_weights_epoch%s.h5' % (model_name, e))\n",
        "                DCGAN_model.save_weights(DCGAN_weights_path, overwrite=True)\n",
        "    except Exception as e:\n",
        "            print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNolsYjGcsAH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" #Set backend to tensorflow\n",
        "image_data_format = \"channels_last\" #Setting image data format for tensorflow\n",
        "K.set_image_data_format(image_data_format)    \n",
        "# Launch training\n",
        "train_GAN(batch_size,n_batch_per_epoch,nb_epoch,generator,model_name,image_data_format,img_dim,bn_mode,label_smoothing,label_flipping,noise_scale,dset,use_mbd,epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2qrpaDDniaW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Display final generated images"
      ]
    },
    {
      "metadata": {
        "id": "jKzEr9e0BVbo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Display final image\n",
        "%pylab inline #Change with %matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from scipy import ndimage, misc\n",
        "\n",
        "\n",
        "img=mpimg.imread('./figures/current_batch.png')\n",
        "\n",
        "#image_resized = misc.imresize(img, (1280, 1280))\n",
        "\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMArMNyOUfz0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#import os, signal\n",
        "#os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}